"""
Azure AKS from-scratch provisioner.

Provides complete AKS cluster provisioning with all required infrastructure
including resource groups, virtual networks, service principals, and node pools.
"""

import logging
from typing import Dict, Any, List
import subprocess
import tempfile

try:
    from azure.identity import ClientSecretCredential
    from azure.mgmt.containerservice import ContainerServiceClient
    from azure.mgmt.resource import ResourceManagementClient
    from azure.mgmt.network import NetworkManagementClient
    from azure.mgmt.authorization import AuthorizationManagementClient
    from azure.core.exceptions import AzureError, ResourceNotFoundError

    AZURE_AVAILABLE = True
except ImportError:
    AZURE_AVAILABLE = False
    ClientSecretCredential = None
    ContainerServiceClient = None
    ResourceManagementClient = None
    NetworkManagementClient = None
    AuthorizationManagementClient = None
    AzureError = Exception
    ResourceNotFoundError = Exception

from .cluster_provisioner import BaseKubernetesProvisioner, ClusterSpec

logger = logging.getLogger(__name__)


class AzureAKSFromScratchProvisioner(BaseKubernetesProvisioner):
    """
    Complete Azure AKS cluster provisioner from blank Azure subscription.

    This provisioner creates all required infrastructure components:
    - Resource group
    - Virtual network with subnets
    - Network security groups
    - Service principal for AKS cluster
    - AKS control plane
    - AKS node pools with auto-scaling
    - kubectl configuration
    - Clustrix namespace and RBAC setup
    """

    def __init__(self, credentials: Dict[str, str], region: str):
        super().__init__(credentials, region)

        if not AZURE_AVAILABLE:
            raise ImportError(
                "azure-mgmt-containerservice required for Azure AKS "
                "provisioning. Install with: pip install "
                "azure-mgmt-containerservice azure-mgmt-resource "
                "azure-mgmt-network azure-mgmt-authorization"
            )

        # Validate required credentials
        required_keys = ["subscription_id", "tenant_id", "client_id", "client_secret"]
        missing_keys = [key for key in required_keys if not credentials.get(key)]
        if missing_keys:
            raise ValueError(f"Missing Azure credentials: {missing_keys}")

        # Initialize Azure credentials and clients
        self.subscription_id = credentials["subscription_id"]
        self.tenant_id = credentials["tenant_id"]
        self.client_id = credentials["client_id"]
        self.client_secret = credentials["client_secret"]

        self.credential = ClientSecretCredential(
            tenant_id=self.tenant_id,
            client_id=self.client_id,
            client_secret=self.client_secret,
        )

        # Initialize Azure clients
        self.resource_client = ResourceManagementClient(
            self.credential, self.subscription_id
        )
        self.network_client = NetworkManagementClient(
            self.credential, self.subscription_id
        )
        self.container_client = ContainerServiceClient(
            self.credential, self.subscription_id
        )
        self.auth_client = AuthorizationManagementClient(
            self.credential, self.subscription_id
        )

        # Track created resources for cleanup
        self.created_resources: Dict[str, List[str]] = {
            "resource_groups": [],
            "virtual_networks": [],
            "subnets": [],
            "network_security_groups": [],
            "service_principals": [],
            "aks_clusters": [],
            "node_pools": [],
        }

    def validate_credentials(self) -> bool:
        """Validate Azure credentials and required permissions."""
        try:
            # Test basic Azure access by listing resource groups
            list(self.resource_client.resource_groups.list())
            logger.info(
                f"âœ… Azure credentials validated for subscription: {self.subscription_id}"
            )

            # Check required service access (basic check)
            required_services = ["containerservice", "network", "authorization"]
            for service in required_services:
                try:
                    # Simple API call to test permissions
                    if service == "containerservice":
                        list(self.container_client.managed_clusters.list())
                    elif service == "network":
                        list(self.network_client.virtual_networks.list_all())
                    elif service == "authorization":
                        # Test authorization access
                        pass

                    logger.debug(f"âœ… {service.upper()} service access confirmed")
                except Exception as e:
                    logger.warning(f"âš ï¸ Limited {service.upper()} permissions: {e}")

            return True

        except Exception as e:
            logger.error(f"âŒ Azure credential validation failed: {e}")
            return False

    def provision_complete_infrastructure(self, spec: ClusterSpec) -> Dict[str, Any]:
        """
        Create complete AKS cluster infrastructure from scratch.

        Steps:
        1. Create resource group
        2. Create virtual network and subnets
        3. Create network security groups
        4. Create service principal for AKS
        5. Create AKS control plane
        6. Create and configure node pools
        7. Configure kubectl access
        8. Set up Clustrix namespace and RBAC
        9. Verify cluster is ready for jobs
        """
        logger.info(f"ðŸš€ Starting AKS cluster provisioning: {spec.cluster_name}")

        try:
            # Step 1: Create resource group
            resource_group_config = self._create_resource_group(spec)

            # Step 2: Create network infrastructure
            network_config = self._create_network_infrastructure(
                spec, resource_group_config
            )

            # Step 3: Create service principal
            sp_config = self._create_service_principal(spec)

            # Step 4: Create AKS control plane
            cluster_info = self._create_aks_control_plane(
                spec, resource_group_config, network_config, sp_config
            )

            # Step 5: Create node pools
            self._create_node_pools(
                spec, cluster_info, resource_group_config, network_config
            )

            # Step 6: Configure kubectl access
            kubectl_config = self._configure_kubectl_access(
                cluster_info, resource_group_config
            )

            # Step 7: Set up Clustrix environment
            self._setup_clustrix_environment(cluster_info, kubectl_config)

            # Step 8: Verify cluster ready
            self._verify_cluster_operational(
                cluster_info["cluster_name"], resource_group_config["name"]
            )

            result = {
                "cluster_id": cluster_info["cluster_name"],
                "cluster_name": cluster_info["cluster_name"],
                "provider": "azure",
                "region": self.region,
                "endpoint": cluster_info["fqdn"],
                "resource_group": resource_group_config["name"],
                "version": cluster_info["version"],
                "node_count": spec.node_count,
                "vm_size": spec.azure_vm_size,
                "virtual_network": network_config["vnet_name"],
                "subnet": network_config["subnet_name"],
                "kubectl_config": kubectl_config,
                "ready_for_jobs": True,
                "created_resources": self.created_resources.copy(),
            }

            logger.info(f"âœ… AKS cluster provisioning completed: {spec.cluster_name}")
            return result

        except Exception as e:
            logger.error(f"âŒ AKS cluster provisioning failed: {e}")
            # Attempt cleanup of any created resources
            self._cleanup_failed_provisioning(spec.cluster_name)
            raise

    def _create_resource_group(self, spec: ClusterSpec) -> Dict[str, Any]:
        """Create Azure resource group."""
        logger.info("ðŸ—ï¸ Creating resource group...")

        resource_group_name = f"clustrix-aks-rg-{spec.cluster_name}"

        resource_group_params = {
            "location": self.region,
            "tags": {
                "clustrix:managed": "true",
                "clustrix:cluster": spec.cluster_name,
                "clustrix:provider": "azure",
            },
        }

        self.resource_client.resource_groups.create_or_update(
            resource_group_name, resource_group_params
        )

        self.created_resources["resource_groups"].append(resource_group_name)

        logger.info(f"âœ… Created resource group: {resource_group_name}")
        return {"name": resource_group_name, "location": self.region}

    def _create_network_infrastructure(
        self, spec: ClusterSpec, rg_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Create virtual network with all networking components."""
        logger.info("ðŸŒ Creating network infrastructure...")

        vnet_name = f"clustrix-aks-vnet-{spec.cluster_name}"
        subnet_name = f"clustrix-aks-subnet-{spec.cluster_name}"
        nsg_name = f"clustrix-aks-nsg-{spec.cluster_name}"

        # Create Network Security Group
        nsg_params = {
            "location": self.region,
            "security_rules": [
                {
                    "name": "AllowSSH",
                    "priority": 1000,
                    "direction": "Inbound",
                    "access": "Allow",
                    "protocol": "Tcp",
                    "source_port_range": "*",
                    "destination_port_range": "22",
                    "source_address_prefix": "*",
                    "destination_address_prefix": "*",
                },
                {
                    "name": "AllowHTTPS",
                    "priority": 1001,
                    "direction": "Inbound",
                    "access": "Allow",
                    "protocol": "Tcp",
                    "source_port_range": "*",
                    "destination_port_range": "443",
                    "source_address_prefix": "*",
                    "destination_address_prefix": "*",
                },
            ],
            "tags": {"clustrix:cluster": spec.cluster_name},
        }

        nsg = self.network_client.network_security_groups.begin_create_or_update(
            rg_config["name"], nsg_name, nsg_params
        ).result()

        self.created_resources["network_security_groups"].append(
            f"{rg_config['name']}/{nsg_name}"
        )

        # Create Virtual Network
        vnet_params = {
            "location": self.region,
            "address_space": {"address_prefixes": ["10.0.0.0/8"]},
            "tags": {"clustrix:cluster": spec.cluster_name},
        }

        vnet = self.network_client.virtual_networks.begin_create_or_update(
            rg_config["name"], vnet_name, vnet_params
        ).result()

        self.created_resources["virtual_networks"].append(
            f"{rg_config['name']}/{vnet_name}"
        )

        # Create Subnet
        subnet_params = {
            "address_prefix": "10.240.0.0/16",
            "network_security_group": {"id": nsg.id},
        }

        subnet = self.network_client.subnets.begin_create_or_update(
            rg_config["name"], vnet_name, subnet_name, subnet_params
        ).result()

        self.created_resources["subnets"].append(
            f"{rg_config['name']}/{vnet_name}/{subnet_name}"
        )

        logger.info(f"âœ… Created network infrastructure: {vnet_name}")
        return {
            "vnet_name": vnet_name,
            "vnet_id": vnet.id,
            "subnet_name": subnet_name,
            "subnet_id": subnet.id,
            "nsg_name": nsg_name,
            "nsg_id": nsg.id,
        }

    def _create_service_principal(self, spec: ClusterSpec) -> Dict[str, Any]:
        """Create service principal for AKS cluster."""
        logger.info("ðŸ‘¤ Creating service principal...")

        # For simplified implementation, we'll use the existing service principal
        # In a full implementation, you would create a new service principal
        # specifically for this AKS cluster

        return {"client_id": self.client_id, "client_secret": self.client_secret}

    def _create_aks_control_plane(
        self,
        spec: ClusterSpec,
        rg_config: Dict[str, Any],
        network_config: Dict[str, Any],
        sp_config: Dict[str, Any],
    ) -> Dict[str, Any]:
        """Create AKS control plane."""
        logger.info("ðŸŽ›ï¸ Creating AKS control plane...")

        cluster_params = {
            "location": self.region,
            "service_principal_profile": {
                "client_id": sp_config["client_id"],
                "secret": sp_config["client_secret"],
            },
            "dns_prefix": f"clustrix-{spec.cluster_name}",
            "kubernetes_version": spec.kubernetes_version,
            "agent_pool_profiles": [
                {
                    "name": "default",
                    "count": spec.node_count,
                    "vm_size": spec.azure_vm_size,
                    "os_type": "Linux",
                    "vnet_subnet_id": network_config["subnet_id"],
                    "enable_auto_scaling": True,
                    "min_count": max(1, spec.node_count // 2),
                    "max_count": spec.node_count * 2,
                    "type": "VirtualMachineScaleSets",
                    "mode": "System",
                }
            ],
            "network_profile": {
                "network_plugin": "azure",
                "service_cidr": "10.0.0.0/16",
                "dns_service_ip": "10.0.0.10",
                "docker_bridge_cidr": "172.17.0.1/16",
            },
            "enable_rbac": True,
            "tags": {"clustrix:managed": "true", "clustrix:cluster": spec.cluster_name},
        }

        # Create AKS cluster
        logger.info("â³ Creating AKS cluster (this may take several minutes)...")
        cluster_operation = (
            self.container_client.managed_clusters.begin_create_or_update(
                rg_config["name"], spec.cluster_name, cluster_params
            )
        )

        cluster = cluster_operation.result(timeout=3600)  # 1 hour timeout
        self.created_resources["aks_clusters"].append(
            f"{rg_config['name']}/{spec.cluster_name}"
        )

        logger.info(f"âœ… AKS control plane ready: {cluster.fqdn}")
        return {
            "cluster_name": cluster.name,
            "fqdn": f"https://{cluster.fqdn}",
            "location": cluster.location,
            "version": cluster.kubernetes_version,
            "provisioning_state": cluster.provisioning_state,
            "resource_group": rg_config["name"],
        }

    def _create_node_pools(
        self,
        spec: ClusterSpec,
        cluster_info: Dict[str, Any],
        rg_config: Dict[str, Any],
        network_config: Dict[str, Any],
    ) -> Dict[str, Any]:
        """Configure AKS node pools (already created with cluster)."""
        logger.info("ðŸ’» Configuring AKS node pools...")

        # The initial node pool was created with the cluster
        # In a more advanced implementation, we might create additional node pools here

        logger.info("âœ… Node pools configured")
        return {"default_pool": "default"}

    def _configure_kubectl_access(
        self, cluster_info: Dict[str, Any], rg_config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Configure kubectl access to the cluster."""
        logger.info("âš™ï¸ Configuring kubectl access...")

        try:
            # Get cluster credentials using Azure CLI
            credentials = (
                self.container_client.managed_clusters.list_cluster_user_credentials(
                    rg_config["name"], cluster_info["cluster_name"]
                )
            )

            if credentials.kubeconfigs:
                # Parse kubeconfig from the credentials
                import base64
                import yaml

                kubeconfig_data = base64.b64decode(
                    credentials.kubeconfigs[0].value
                ).decode("utf-8")
                kubeconfig = yaml.safe_load(kubeconfig_data)

                return kubeconfig
            else:
                raise RuntimeError("No kubeconfig found in cluster credentials")

        except Exception as e:
            logger.error(f"Failed to get cluster credentials: {e}")
            # Return a basic kubeconfig structure
            return {
                "apiVersion": "v1",
                "kind": "Config",
                "clusters": [
                    {
                        "cluster": {"server": cluster_info["fqdn"]},
                        "name": cluster_info["cluster_name"],
                    }
                ],
                "contexts": [
                    {
                        "context": {
                            "cluster": cluster_info["cluster_name"],
                            "user": cluster_info["cluster_name"],
                        },
                        "name": cluster_info["cluster_name"],
                    }
                ],
                "current-context": cluster_info["cluster_name"],
                "users": [
                    {
                        "name": cluster_info["cluster_name"],
                        "user": {
                            "exec": {
                                "apiVersion": "client.authentication.k8s.io/v1beta1",
                                "command": "az",
                                "args": [
                                    "aks",
                                    "get-credentials",
                                    "--resource-group",
                                    rg_config["name"],
                                    "--name",
                                    cluster_info["cluster_name"],
                                    "--format",
                                    "exec",
                                ],
                            }
                        },
                    }
                ],
            }

    def _setup_clustrix_environment(
        self, cluster_info: Dict[str, Any], kubectl_config: Dict[str, Any]
    ) -> None:
        """Set up Clustrix namespace and RBAC."""
        logger.info("ðŸ”§ Setting up Clustrix environment...")

        try:
            # Write kubeconfig to temporary file
            with tempfile.NamedTemporaryFile(
                mode="w", suffix=".yaml", delete=False
            ) as f:
                import yaml

                yaml.dump(kubectl_config, f)
                kubeconfig_path = f.name

            # Create namespace
            subprocess.run(
                [
                    "kubectl",
                    "--kubeconfig",
                    kubeconfig_path,
                    "create",
                    "namespace",
                    "clustrix",
                ],
                check=False,
                capture_output=True,
            )

            # Create service account
            subprocess.run(
                [
                    "kubectl",
                    "--kubeconfig",
                    kubeconfig_path,
                    "create",
                    "serviceaccount",
                    "clustrix-worker",
                    "--namespace",
                    "clustrix",
                ],
                check=False,
                capture_output=True,
            )

            # Create cluster role binding
            subprocess.run(
                [
                    "kubectl",
                    "--kubeconfig",
                    kubeconfig_path,
                    "create",
                    "clusterrolebinding",
                    "clustrix-worker-binding",
                    "--clusterrole",
                    "cluster-admin",
                    "--serviceaccount",
                    "clustrix:clustrix-worker",
                ],
                check=False,
                capture_output=True,
            )

            logger.info("âœ… Clustrix environment configured")

        except Exception as e:
            logger.warning(f"âš ï¸ Failed to configure Clustrix environment: {e}")
        finally:
            # Clean up temporary kubeconfig file
            import os

            try:
                os.unlink(kubeconfig_path)
            except Exception:
                pass

    def _verify_cluster_operational(
        self, cluster_name: str, resource_group_name: str
    ) -> None:
        """Verify cluster is ready for job submission."""
        logger.info("ðŸ” Verifying cluster is operational...")

        try:
            # Check cluster status
            cluster = self.container_client.managed_clusters.get(
                resource_group_name, cluster_name
            )
            if cluster.provisioning_state != "Succeeded":
                raise RuntimeError(f"Cluster not ready: {cluster.provisioning_state}")

            # Check agent pools
            agent_pools = list(
                self.container_client.agent_pools.list(
                    resource_group_name, cluster_name
                )
            )
            for pool in agent_pools:
                if pool.provisioning_state != "Succeeded":
                    raise RuntimeError(
                        f"Agent pool not ready: {pool.provisioning_state}"
                    )

            logger.info("âœ… Cluster verification completed")

        except Exception as e:
            logger.error(f"âŒ Cluster verification failed: {e}")
            raise

    def destroy_cluster_infrastructure(self, cluster_id: str) -> bool:
        """Destroy cluster and all associated infrastructure."""
        logger.info(f"ðŸ§¹ Destroying AKS cluster: {cluster_id}")

        try:
            # Find resource group for this cluster
            resource_group_name = None
            for rg_name in self.created_resources.get("resource_groups", []):
                if cluster_id in rg_name:
                    resource_group_name = rg_name
                    break

            if not resource_group_name:
                # Try to find cluster directly
                for cluster_path in self.created_resources.get("aks_clusters", []):
                    if cluster_id in cluster_path:
                        resource_group_name = cluster_path.split("/")[0]
                        break

            if resource_group_name:
                # Delete entire resource group (this deletes all contained resources)
                logger.info(f"Deleting resource group: {resource_group_name}")
                delete_operation = self.resource_client.resource_groups.begin_delete(
                    resource_group_name
                )
                delete_operation.result(timeout=3600)  # 1 hour timeout
                logger.info(f"âœ… Deleted resource group: {resource_group_name}")
            else:
                logger.warning(
                    f"Could not find resource group for cluster: {cluster_id}"
                )

            return True

        except Exception as e:
            logger.error(f"âŒ Failed to destroy cluster: {e}")
            return False

    def get_cluster_status(self, cluster_id: str) -> Dict[str, Any]:
        """Get detailed cluster status and health information."""
        try:
            # Find resource group for this cluster
            resource_group_name = None
            for rg_name in self.created_resources.get("resource_groups", []):
                if cluster_id in rg_name:
                    resource_group_name = rg_name
                    break

            if not resource_group_name:
                # Try to find from existing clusters
                for cluster_path in self.created_resources.get("aks_clusters", []):
                    if cluster_id in cluster_path:
                        resource_group_name = cluster_path.split("/")[0]
                        break

            if not resource_group_name:
                return {
                    "cluster_id": cluster_id,
                    "status": "NOT_FOUND",
                    "ready_for_jobs": False,
                }

            cluster = self.container_client.managed_clusters.get(
                resource_group_name, cluster_id
            )

            # Check agent pools
            agent_pools = list(
                self.container_client.agent_pools.list(resource_group_name, cluster_id)
            )
            node_status = []
            for pool in agent_pools:
                node_status.append(
                    {
                        "name": pool.name,
                        "status": pool.provisioning_state,
                        "node_count": pool.count,
                    }
                )

            return {
                "cluster_id": cluster_id,
                "status": cluster.provisioning_state,
                "endpoint": f"https://{cluster.fqdn}",
                "version": cluster.kubernetes_version,
                "location": cluster.location,
                "node_pools": node_status,
                "ready_for_jobs": (
                    cluster.provisioning_state == "Succeeded"
                    and all(np["status"] == "Succeeded" for np in node_status)
                ),
            }

        except ResourceNotFoundError:
            return {
                "cluster_id": cluster_id,
                "status": "NOT_FOUND",
                "ready_for_jobs": False,
            }
        except Exception as e:
            logger.error(f"Error getting cluster status: {e}")
            raise

    def _cleanup_failed_provisioning(self, cluster_name: str) -> None:
        """Clean up resources if provisioning fails."""
        logger.info("ðŸ§¹ Cleaning up failed provisioning...")
        try:
            self._cleanup_all_resources()
        except Exception as e:
            logger.error(f"Error during cleanup: {e}")

    def _cleanup_all_resources(self) -> None:
        """Clean up all tracked resources."""
        logger.info("ðŸ§¹ Cleaning up all created resources...")

        # For Azure, the simplest approach is to delete resource groups
        # which automatically deletes all contained resources
        for rg_name in self.created_resources.get("resource_groups", []):
            try:
                logger.info(f"Deleting resource group: {rg_name}")
                delete_operation = self.resource_client.resource_groups.begin_delete(
                    rg_name
                )
                delete_operation.result(timeout=3600)
                logger.info(f"âœ… Deleted resource group: {rg_name}")
            except Exception as e:
                logger.warning(f"Failed to delete resource group {rg_name}: {e}")
