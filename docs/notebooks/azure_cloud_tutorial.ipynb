{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "azure-title",
   "metadata": {},
   "source": [
    "# Microsoft Azure Cloud Tutorial\n",
    "\n",
    "This tutorial demonstrates how to use Clustrix with Microsoft Azure cloud infrastructure for scalable distributed computing.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContextLab/clustrix/blob/master/docs/notebooks/azure_cloud_tutorial.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "Azure provides several services that integrate well with Clustrix:\n",
    "\n",
    "- **Azure Virtual Machines**: Scalable compute instances\n",
    "- **Azure Batch**: Managed job scheduling service\n",
    "- **Azure CycleCloud**: HPC cluster orchestration\n",
    "- **Azure Machine Learning Compute**: ML-optimized infrastructure\n",
    "- **Azure Container Instances**: Serverless containers\n",
    "- **Azure Blob Storage**: Object storage for data and results\n",
    "- **Azure Virtual Network**: Network isolation and security\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. Azure subscription with appropriate permissions\n",
    "2. Azure CLI installed and configured\n",
    "3. SSH key pair for VM access\n",
    "4. Basic understanding of Azure services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "installation",
   "metadata": {},
   "source": [
    "## Installation and Setup\n",
    "\n",
    "Install Clustrix with Azure dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Clustrix with Azure support\n",
    "!pip install clustrix azure-identity azure-mgmt-compute azure-mgmt-network azure-storage-blob\n",
    "\n",
    "# Import required libraries\n",
    "import clustrix\n",
    "from clustrix import cluster, configure\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.mgmt.compute import ComputeManagementClient\n",
    "from azure.mgmt.network import NetworkManagementClient\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "azure-credentials",
   "metadata": {},
   "source": [
    "## Azure Authentication Setup\n",
    "\n",
    "Configure your Azure credentials. You can do this in several ways:\n",
    "\n",
    "### Option 1: Azure CLI Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "azure-cli-auth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login with Azure CLI (run this in terminal)\n",
    "# az login\n",
    "\n",
    "# Set your subscription\n",
    "# az account set --subscription \"your-subscription-id\"\n",
    "\n",
    "# Verify authentication\n",
    "!az account show --output table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "azure-creds-env",
   "metadata": {},
   "source": [
    "### Option 2: Service Principal Authentication"
   ]
  },
  {
   "cell_type": "code",
   "id": "service-principal",
   "metadata": {},
   "outputs": [],
   "source": "# Set Azure credentials as environment variables\n# os.environ['AZURE_CLIENT_ID'] = 'your-client-id'\n# os.environ['AZURE_CLIENT_SECRET'] = 'your-client-secret'\n# os.environ['AZURE_TENANT_ID'] = 'your-tenant-id'\n\n# Test Azure connection\ntry:\n    credential = DefaultAzureCredential()\n    subscription_id = 'your-subscription-id'  # Replace with actual ID\n    \n    compute_client = ComputeManagementClient(credential, subscription_id)\n    # Test by listing VM sizes in East US\n    vm_sizes = list(compute_client.virtual_machine_sizes.list('eastus'))\n    print(f\"Successfully connected to Azure. Available VM sizes: {len(vm_sizes)}\")\nexcept Exception as e:\n    print(f\"Azure connection failed: {e}\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1hqa6m0oltd",
   "source": "**Note**: Make sure you have set up authentication and have the correct subscription ID.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "vm-setup",
   "metadata": {},
   "source": [
    "## Method 1: Azure Virtual Machines Configuration\n",
    "\n",
    "### Create Azure VM for Clustrix"
   ]
  },
  {
   "cell_type": "code",
   "id": "vm-creation",
   "metadata": {},
   "outputs": [],
   "source": "def create_clustrix_vm(resource_group, vm_name, location='eastus', vm_size='Standard_D4s_v3'):\n    \"\"\"\n    Create an Azure VM configured for Clustrix.\n    \n    Args:\n        resource_group: Azure resource group name\n        vm_name: Name for the VM\n        location: Azure region\n        vm_size: VM size (CPU/memory configuration)\n    \n    Returns:\n        VM details including public IP\n    \"\"\"\n    # Cloud-init script for VM setup\n    cloud_init_script = '''\n#cloud-config\npackage_update: true\npackages:\n  - python3\n  - python3-pip\n  - git\n  - htop\n\nruncmd:\n  # Install clustrix and common packages\n  - pip3 install clustrix numpy scipy pandas scikit-learn\n  \n  # Install uv for faster package management\n  - curl -LsSf https://astral.sh/uv/install.sh | sh\n  \n  # Create clustrix user\n  - useradd -m -s /bin/bash clustrix\n  - usermod -aG sudo clustrix\n  - echo \"clustrix ALL=(ALL) NOPASSWD:ALL\" >> /etc/sudoers\n  \n  # Setup SSH for clustrix user\n  - mkdir -p /home/clustrix/.ssh\n  - cp /home/azureuser/.ssh/authorized_keys /home/clustrix/.ssh/\n  - chown -R clustrix:clustrix /home/clustrix/.ssh\n  - chmod 700 /home/clustrix/.ssh\n  - chmod 600 /home/clustrix/.ssh/authorized_keys\n  \n  # Create working directory\n  - mkdir -p /tmp/clustrix\n  - chown clustrix:clustrix /tmp/clustrix\n'''\n    \n    # Example Azure CLI commands (would need to be executed)\n    azure_commands = f\"\"\"\n# Create resource group\naz group create --name {resource_group} --location {location}\n\n# Create VM with cloud-init\naz vm create \\\n  --resource-group {resource_group} \\\n  --name {vm_name} \\\n  --image Ubuntu2204 \\\n  --size {vm_size} \\\n  --admin-username azureuser \\\n  --generate-ssh-keys \\\n  --custom-data cloud-init.txt \\\n  --public-ip-sku Standard \\\n  --tags Purpose=Clustrix Environment=Tutorial\n\n# Get public IP\naz vm show \\\n  --resource-group {resource_group} \\\n  --name {vm_name} \\\n  --show-details \\\n  --query publicIps \\\n  --output tsv\n\"\"\"\n    \n    return {\n        'resource_group': resource_group,\n        'vm_name': vm_name,\n        'location': location,\n        'vm_size': vm_size,\n        'commands': azure_commands,\n        'cloud_init': cloud_init_script\n    }\n\n# Example usage\nvm_config = create_clustrix_vm(\n    resource_group='clustrix-tutorial-rg',\n    vm_name='clustrix-vm-01',\n    location='eastus',\n    vm_size='Standard_D4s_v3'  # 4 vCPUs, 16 GB RAM\n)\n\nprint(\"Azure VM Creation Commands:\")\nprint(vm_config['commands'])\nprint(\"\\nCloud-init script:\")\nprint(vm_config['cloud_init'])",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2qs6d0q31fd",
   "source": "**Execute the Azure CLI commands to create your VM. The cloud-init script will automatically configure Clustrix on the new VM.**",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "clustrix-azure-config",
   "metadata": {},
   "source": [
    "### Configure Clustrix for Azure VM"
   ]
  },
  {
   "cell_type": "code",
   "id": "config-azure-vm",
   "metadata": {},
   "outputs": [],
   "source": "# Configure Clustrix to use your Azure VM\nconfigure(\n    cluster_type=\"ssh\",\n    cluster_host=\"your-vm-public-ip\",  # Replace with actual IP from az vm show\n    username=\"clustrix\",  # or \"azureuser\" if using default user\n    key_file=\"~/.ssh/id_rsa\",  # Azure CLI generated key\n    remote_work_dir=\"/tmp/clustrix\",\n    package_manager=\"auto\",  # Will use uv if available\n    default_cores=4,\n    default_memory=\"8GB\",\n    default_time=\"01:00:00\"\n)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "kh72n7h6uzp",
   "source": "**Replace `your-vm-public-ip` with the actual public IP from your Azure VM.**",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "azure-example",
   "metadata": {},
   "source": [
    "### Example: Remote Computation on Azure VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "azure-vm-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cluster(cores=2, memory=\"4GB\")\n",
    "def azure_numerical_analysis(matrix_size=1000, iterations=10):\n",
    "    \"\"\"Perform numerical analysis on Azure VM.\"\"\"\n",
    "    import numpy as np\n",
    "    import time\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        # Generate random matrix\n",
    "        matrix = np.random.rand(matrix_size, matrix_size)\n",
    "        \n",
    "        # Perform eigenvalue decomposition\n",
    "        start_time = time.time()\n",
    "        eigenvalues = np.linalg.eigvals(matrix)\n",
    "        computation_time = time.time() - start_time\n",
    "        \n",
    "        results.append({\n",
    "            'iteration': i + 1,\n",
    "            'max_eigenvalue': float(np.max(eigenvalues.real)),\n",
    "            'min_eigenvalue': float(np.min(eigenvalues.real)),\n",
    "            'computation_time': computation_time\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'matrix_size': matrix_size,\n",
    "        'total_iterations': iterations,\n",
    "        'average_time': np.mean([r['computation_time'] for r in results]),\n",
    "        'results': results\n",
    "    }\n",
    "\n",
    "# Run computation on Azure VM\n",
    "# result = azure_numerical_analysis(matrix_size=500, iterations=5)\n",
    "# print(f\"Completed {result['total_iterations']} iterations\")\n",
    "# print(f\"Average computation time: {result['average_time']:.3f} seconds\")\n",
    "print(\"Example function defined. Uncomment the lines above to run on your Azure VM.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "azure-batch",
   "metadata": {},
   "source": [
    "## Method 2: Azure Batch Configuration\n",
    "\n",
    "Azure Batch provides managed job scheduling for large-scale parallel workloads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "azure-batch-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_azure_batch_environment():\n",
    "    \"\"\"\n",
    "    Template for setting up Azure Batch environment.\n",
    "    This requires manual setup through Azure portal or CLI.\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_setup_commands = \"\"\"\n",
    "# Create Azure Batch account\n",
    "az batch account create \\\n",
    "  --name clustrixbatch \\\n",
    "  --resource-group clustrix-tutorial-rg \\\n",
    "  --location eastus\n",
    "\n",
    "# Create storage account for Batch\n",
    "az storage account create \\\n",
    "  --name clustrixstorage \\\n",
    "  --resource-group clustrix-tutorial-rg \\\n",
    "  --location eastus \\\n",
    "  --sku Standard_LRS\n",
    "\n",
    "# Link storage to Batch account\n",
    "az batch account set \\\n",
    "  --name clustrixbatch \\\n",
    "  --resource-group clustrix-tutorial-rg \\\n",
    "  --storage-account clustrixstorage\n",
    "\n",
    "# Create Batch pool\n",
    "az batch pool create \\\n",
    "  --id clustrix-pool \\\n",
    "  --vm-size Standard_D2s_v3 \\\n",
    "  --target-dedicated-nodes 2 \\\n",
    "  --image canonical:0001-com-ubuntu-server-jammy:22_04-lts \\\n",
    "  --node-agent-sku-id \"batch.node.ubuntu 22.04\"\n",
    "\n",
    "# Create Batch job\n",
    "az batch job create \\\n",
    "  --id clustrix-job \\\n",
    "  --pool-id clustrix-pool\n",
    "\"\"\"\n",
    "    \n",
    "    batch_config = {\n",
    "        'account_name': 'clustrixbatch',\n",
    "        'account_url': 'https://clustrixbatch.eastus.batch.azure.com',\n",
    "        'resource_group': 'clustrix-tutorial-rg',\n",
    "        'pool_id': 'clustrix-pool',\n",
    "        'job_id': 'clustrix-job'\n",
    "    }\n",
    "    \n",
    "    print(\"Azure Batch Setup Commands:\")\n",
    "    print(batch_setup_commands)\n",
    "    print(\"\\nBatch Configuration:\")\n",
    "    print(json.dumps(batch_config, indent=2))\n",
    "    \n",
    "    return batch_config\n",
    "\n",
    "batch_config = setup_azure_batch_environment()\n",
    "print(\"\\nNote: Azure Batch integration with Clustrix would require custom implementation.\")\n",
    "print(\"Consider using Azure CycleCloud for HPC workloads instead.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cyclecloud",
   "metadata": {},
   "source": [
    "## Method 3: Azure CycleCloud Integration\n",
    "\n",
    "Azure CycleCloud is designed for HPC workloads and provides SLURM integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cyclecloud-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure CycleCloud cluster template for Clustrix\n",
    "cyclecloud_template = \"\"\"\n",
    "# CycleCloud SLURM cluster template\n",
    "# Save as clustrix-slurm.txt and import into CycleCloud\n",
    "\n",
    "[cluster clustrix-slurm]\n",
    "FormLayout = selectionpanel\n",
    "Category = Schedulers\n",
    "IconUrl = static/cloud/cluster/ui/ClusterIcon/slurm.png\n",
    "\n",
    "    [[node defaults]]\n",
    "    UsePublicNetwork = false\n",
    "    Credentials = $Credentials\n",
    "    SubnetId = $SubnetId\n",
    "    Region = $Region\n",
    "    KeyPairLocation = ~/.ssh/cyclecloud.pem\n",
    "    \n",
    "    # Install clustrix on all nodes\n",
    "    [[[configuration]]]\n",
    "    clustrix.version = latest\n",
    "    \n",
    "    [[[cluster-init clustrix:default:1.0.0]]]\n",
    "    \n",
    "    [[node master]]\n",
    "    MachineType = $MasterMachineType\n",
    "    IsReturnProxy = $ReturnProxy\n",
    "    AdditionalClusterInitSpecs = $MasterClusterInitSpecs\n",
    "    \n",
    "        [[[configuration]]]\n",
    "        slurm.version = $configuration_slurm_version\n",
    "        \n",
    "        [[[cluster-init slurm:master:2.7.2]]]\n",
    "        \n",
    "        [[[network-interface eth0]]]\n",
    "        AssociatePublicIpAddress = $UsePublicNetwork\n",
    "\n",
    "    [[nodearray execute]]\n",
    "    MachineType = $ExecuteMachineType\n",
    "    MaxCoreCount = $MaxExecuteCoreCount\n",
    "    Interruptible = $UseLowPrio\n",
    "    AdditionalClusterInitSpecs = $ExecuteClusterInitSpecs\n",
    "    \n",
    "        [[[configuration]]]\n",
    "        slurm.version = $configuration_slurm_version\n",
    "        \n",
    "        [[[cluster-init slurm:execute:2.7.2]]]\n",
    "        \n",
    "        [[[network-interface eth0]]]\n",
    "        AssociatePublicIpAddress = false\n",
    "\n",
    "[parameters About]\n",
    "Order = 1\n",
    "\n",
    "    [[parameters About Clustrix]]\n",
    "    \n",
    "        [[[parameter clustrix]]]\n",
    "        HideLabel = true\n",
    "        Config.Plugin = pico.widget.HtmlTemplateWidget\n",
    "        Config.Template = \"Clustrix-enabled SLURM cluster for distributed computing\"\n",
    "\n",
    "[parameters Required Settings]\n",
    "Order = 10\n",
    "\n",
    "    [[parameters Virtual Machines]]\n",
    "    Description = \"Configure the VM types and sizes\"\n",
    "    Order = 20\n",
    "\n",
    "        [[[parameter Region]]]\n",
    "        Label = Region\n",
    "        Description = Deployment Location\n",
    "        ParameterType = Cloud.Region\n",
    "        DefaultValue = eastus\n",
    "\n",
    "        [[[parameter MasterMachineType]]]\n",
    "        Label = Master VM Type\n",
    "        Description = Master node VM type\n",
    "        ParameterType = Cloud.MachineType\n",
    "        DefaultValue = Standard_D4s_v3\n",
    "\n",
    "        [[[parameter ExecuteMachineType]]]\n",
    "        Label = Execute VM Type\n",
    "        Description = Execute node VM type\n",
    "        ParameterType = Cloud.MachineType\n",
    "        DefaultValue = Standard_H16r\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def configure_for_cyclecloud(master_ip, cluster_name=\"clustrix-slurm\"):\n",
    "    \"\"\"Configure Clustrix to use Azure CycleCloud SLURM cluster.\"\"\"\n",
    "    configure(\n",
    "        cluster_type=\"slurm\",\n",
    "        cluster_host=master_ip,\n",
    "        username=\"cyclecloud\",  # Default CycleCloud user\n",
    "        key_file=\"~/.ssh/cyclecloud.pem\",\n",
    "        remote_work_dir=\"/shared/clustrix\",  # Use shared storage\n",
    "        package_manager=\"uv\",\n",
    "        module_loads=[\"python3\"],\n",
    "        environment_variables={\n",
    "            \"CLUSTRIX_CLUSTER\": cluster_name\n",
    "        },\n",
    "        default_cores=8,\n",
    "        default_memory=\"16GB\",\n",
    "        default_time=\"02:00:00\",\n",
    "        default_partition=\"hpc\"\n",
    "    )\n",
    "    print(f\"Configured Clustrix for CycleCloud cluster: {cluster_name}\")\n",
    "\n",
    "print(\"CycleCloud Template:\")\n",
    "print(cyclecloud_template)\n",
    "\n",
    "# Example configuration\n",
    "# configure_for_cyclecloud(\"10.1.0.4\", \"my-clustrix-cluster\")\n",
    "print(\"\\nCycleCloud provides the best HPC integration for Azure + Clustrix.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "azure-storage",
   "metadata": {},
   "source": [
    "## Data Management with Azure Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blob-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cluster(cores=2, memory=\"4GB\")\n",
    "def process_blob_data(storage_account, container_name, input_blob, output_blob, storage_key=None):\n",
    "    \"\"\"Process data from Azure Blob Storage and save results back.\"\"\"\n",
    "    from azure.storage.blob import BlobServiceClient\n",
    "    from azure.identity import DefaultAzureCredential\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import io\n",
    "    \n",
    "    # Initialize Blob Service Client\n",
    "    if storage_key:\n",
    "        account_url = f\"https://{storage_account}.blob.core.windows.net\"\n",
    "        blob_service_client = BlobServiceClient(account_url=account_url, credential=storage_key)\n",
    "    else:\n",
    "        # Use managed identity or Azure CLI authentication\n",
    "        account_url = f\"https://{storage_account}.blob.core.windows.net\"\n",
    "        credential = DefaultAzureCredential()\n",
    "        blob_service_client = BlobServiceClient(account_url=account_url, credential=credential)\n",
    "    \n",
    "    # Download data from blob storage\n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=input_blob)\n",
    "    blob_data = blob_client.download_blob()\n",
    "    data = pickle.loads(blob_data.readall())\n",
    "    \n",
    "    # Process the data\n",
    "    processed_data = {\n",
    "        'original_shape': data.shape if hasattr(data, 'shape') else len(data),\n",
    "        'mean': float(np.mean(data)) if hasattr(data, '__iter__') else float(data),\n",
    "        'std': float(np.std(data)) if hasattr(data, '__iter__') else 0.0,\n",
    "        'max': float(np.max(data)) if hasattr(data, '__iter__') else float(data),\n",
    "        'min': float(np.min(data)) if hasattr(data, '__iter__') else float(data),\n",
    "        'processing_timestamp': time.time(),\n",
    "        'processed_on': 'azure-vm'\n",
    "    }\n",
    "    \n",
    "    # Upload results to blob storage\n",
    "    output_buffer = io.BytesIO()\n",
    "    pickle.dump(processed_data, output_buffer)\n",
    "    output_buffer.seek(0)\n",
    "    \n",
    "    output_blob_client = blob_service_client.get_blob_client(container=container_name, blob=output_blob)\n",
    "    output_blob_client.upload_blob(output_buffer.getvalue(), overwrite=True)\n",
    "    \n",
    "    return f\"Processed data saved to blob: {output_blob}\"\n",
    "\n",
    "# Utility functions for Azure Blob Storage\n",
    "def upload_to_blob(data, storage_account, container_name, blob_name, storage_key=None):\n",
    "    \"\"\"Upload data to Azure Blob Storage.\"\"\"\n",
    "    if storage_key:\n",
    "        account_url = f\"https://{storage_account}.blob.core.windows.net\"\n",
    "        blob_service_client = BlobServiceClient(account_url=account_url, credential=storage_key)\n",
    "    else:\n",
    "        account_url = f\"https://{storage_account}.blob.core.windows.net\"\n",
    "        credential = DefaultAzureCredential()\n",
    "        blob_service_client = BlobServiceClient(account_url=account_url, credential=credential)\n",
    "    \n",
    "    buffer = io.BytesIO()\n",
    "    pickle.dump(data, buffer)\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "    blob_client.upload_blob(buffer.getvalue(), overwrite=True)\n",
    "    print(f\"Data uploaded to blob: {blob_name}\")\n",
    "\n",
    "def download_from_blob(storage_account, container_name, blob_name, storage_key=None):\n",
    "    \"\"\"Download data from Azure Blob Storage.\"\"\"\n",
    "    if storage_key:\n",
    "        account_url = f\"https://{storage_account}.blob.core.windows.net\"\n",
    "        blob_service_client = BlobServiceClient(account_url=account_url, credential=storage_key)\n",
    "    else:\n",
    "        account_url = f\"https://{storage_account}.blob.core.windows.net\"\n",
    "        credential = DefaultAzureCredential()\n",
    "        blob_service_client = BlobServiceClient(account_url=account_url, credential=credential)\n",
    "    \n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "    blob_data = blob_client.download_blob()\n",
    "    return pickle.loads(blob_data.readall())\n",
    "\n",
    "# Example usage:\n",
    "# sample_data = np.random.rand(1000, 50)\n",
    "# upload_to_blob(sample_data, 'yourstorageaccount', 'data', 'input/sample.pkl')\n",
    "# result = process_blob_data('yourstorageaccount', 'data', 'input/sample.pkl', 'output/results.pkl')\n",
    "print(\"Azure Blob Storage integration functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "azure-ml",
   "metadata": {},
   "source": [
    "## Azure Machine Learning Compute Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "azure-ml-compute",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_azure_ml_compute():\n",
    "    \"\"\"\n",
    "    Template for setting up Azure ML compute clusters.\n",
    "    These can be used with Clustrix for ML workloads.\n",
    "    \"\"\"\n",
    "    \n",
    "    aml_setup_commands = \"\"\"\n",
    "# Create Azure ML workspace\n",
    "az ml workspace create \\\n",
    "  --name clustrix-ml-workspace \\\n",
    "  --resource-group clustrix-tutorial-rg \\\n",
    "  --location eastus\n",
    "\n",
    "# Create compute cluster\n",
    "az ml compute create \\\n",
    "  --name clustrix-compute \\\n",
    "  --type amlcompute \\\n",
    "  --min-instances 0 \\\n",
    "  --max-instances 4 \\\n",
    "  --size Standard_DS3_v2 \\\n",
    "  --workspace-name clustrix-ml-workspace \\\n",
    "  --resource-group clustrix-tutorial-rg\n",
    "\n",
    "# Create compute instance for development\n",
    "az ml compute create \\\n",
    "  --name clustrix-dev-instance \\\n",
    "  --type computeinstance \\\n",
    "  --size Standard_DS3_v2 \\\n",
    "  --workspace-name clustrix-ml-workspace \\\n",
    "  --resource-group clustrix-tutorial-rg\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"Azure ML Compute Setup Commands:\")\n",
    "    print(aml_setup_commands)\n",
    "    \n",
    "    return {\n",
    "        'workspace': 'clustrix-ml-workspace',\n",
    "        'compute_cluster': 'clustrix-compute',\n",
    "        'compute_instance': 'clustrix-dev-instance'\n",
    "    }\n",
    "\n",
    "@cluster(cores=4, memory=\"8GB\")\n",
    "def azure_ml_training_job(dataset_params, model_params):\n",
    "    \"\"\"Example ML training job that could run on Azure ML compute.\"\"\"\n",
    "    import numpy as np\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.datasets import make_classification\n",
    "    import time\n",
    "    \n",
    "    # Generate synthetic dataset (in real scenario, load from Azure ML datasets)\n",
    "    X, y = make_classification(\n",
    "        n_samples=dataset_params['n_samples'],\n",
    "        n_features=dataset_params['n_features'],\n",
    "        n_classes=dataset_params['n_classes'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    start_time = time.time()\n",
    "    model = RandomForestClassifier(**model_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'training_time': training_time,\n",
    "        'training_samples': len(X_train),\n",
    "        'test_samples': len(X_test),\n",
    "        'feature_importance': model.feature_importances_.tolist()[:10],  # Top 10\n",
    "        'model_params': model_params,\n",
    "        'dataset_params': dataset_params\n",
    "    }\n",
    "\n",
    "aml_config = setup_azure_ml_compute()\n",
    "\n",
    "# Example usage:\n",
    "# dataset_config = {'n_samples': 10000, 'n_features': 20, 'n_classes': 3}\n",
    "# model_config = {'n_estimators': 100, 'max_depth': 10, 'random_state': 42, 'n_jobs': -1}\n",
    "# result = azure_ml_training_job(dataset_config, model_config)\n",
    "# print(f\"Model trained with accuracy: {result['accuracy']:.4f}\")\n",
    "\n",
    "print(\"Azure ML integration example defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "azure-security",
   "metadata": {},
   "source": [
    "## Security Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "azure-security-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_azure_security():\n",
    "    \"\"\"\n",
    "    Security configuration templates for Azure resources.\n",
    "    \"\"\"\n",
    "    \n",
    "    security_commands = \"\"\"\n",
    "# Create Network Security Group with restrictive rules\n",
    "az network nsg create \\\n",
    "  --name clustrix-nsg \\\n",
    "  --resource-group clustrix-tutorial-rg\n",
    "\n",
    "# Allow SSH only from your IP\n",
    "az network nsg rule create \\\n",
    "  --name SSH \\\n",
    "  --nsg-name clustrix-nsg \\\n",
    "  --resource-group clustrix-tutorial-rg \\\n",
    "  --priority 1000 \\\n",
    "  --source-address-prefixes YOUR_IP/32 \\\n",
    "  --source-port-ranges '*' \\\n",
    "  --destination-address-prefixes '*' \\\n",
    "  --destination-port-ranges 22 \\\n",
    "  --access Allow \\\n",
    "  --protocol Tcp\n",
    "\n",
    "# Create Key Vault for secrets\n",
    "az keyvault create \\\n",
    "  --name clustrix-keyvault-$(date +%s) \\\n",
    "  --resource-group clustrix-tutorial-rg \\\n",
    "  --location eastus \\\n",
    "  --enable-disk-encryption\n",
    "\n",
    "# Enable managed identity for VMs\n",
    "az vm identity assign \\\n",
    "  --name clustrix-vm-01 \\\n",
    "  --resource-group clustrix-tutorial-rg\n",
    "\n",
    "# Setup private endpoint for storage\n",
    "az storage account update \\\n",
    "  --name clustrixstorage \\\n",
    "  --resource-group clustrix-tutorial-rg \\\n",
    "  --default-action Deny\n",
    "\"\"\"\n",
    "    \n",
    "    security_checklist = \"\"\"\n",
    "Azure Security Checklist for Clustrix:\n",
    "\n",
    "✓ Use Azure Active Directory for authentication\n",
    "✓ Enable managed identities instead of service principals when possible\n",
    "✓ Restrict Network Security Groups to your IP address only\n",
    "✓ Use private endpoints for storage accounts\n",
    "✓ Enable disk encryption for all VMs\n",
    "✓ Use Azure Key Vault for secrets and certificates\n",
    "✓ Enable Azure Security Center recommendations\n",
    "✓ Use Azure Private Link for service connectivity\n",
    "✓ Enable diagnostic logging and monitoring\n",
    "✓ Implement Azure Policy for compliance\n",
    "✓ Use Azure Defender for cloud workload protection\n",
    "✓ Regularly rotate access keys and certificates\n",
    "✓ Set up cost alerts and spending limits\n",
    "✓ Tag all resources for governance and cost tracking\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"Azure Security Setup Commands:\")\n",
    "    print(security_commands)\n",
    "    print(\"\\nSecurity Checklist:\")\n",
    "    print(security_checklist)\n",
    "    \n",
    "    return {\n",
    "        'nsg_name': 'clustrix-nsg',\n",
    "        'keyvault_name': 'clustrix-keyvault',\n",
    "        'security_commands': security_commands\n",
    "    }\n",
    "\n",
    "security_config = setup_azure_security()\n",
    "print(\"Security configuration templates generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cost-management",
   "metadata": {},
   "source": [
    "## Cost Management and Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "azure-cost-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def azure_cost_optimization_guide():\n",
    "    \"\"\"\n",
    "    Cost optimization strategies for Azure + Clustrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    cost_tips = \"\"\"\n",
    "Azure Cost Optimization for Clustrix:\n",
    "\n",
    "1. Compute Optimization:\n",
    "   - Use Azure Spot VMs for non-critical workloads (up to 90% savings)\n",
    "   - Choose B-series burstable VMs for variable workloads\n",
    "   - Use reserved instances for predictable workloads (1-3 year terms)\n",
    "   - Enable auto-shutdown for dev/test VMs\n",
    "   - Right-size VMs based on actual usage\n",
    "\n",
    "2. Storage Optimization:\n",
    "   - Use appropriate storage tiers (Hot, Cool, Archive)\n",
    "   - Enable lifecycle management for blob storage\n",
    "   - Use managed disks with appropriate performance tiers\n",
    "   - Implement data deduplication and compression\n",
    "\n",
    "3. Network Optimization:\n",
    "   - Minimize data transfer between regions\n",
    "   - Use Azure CDN for static content\n",
    "   - Optimize data transfer patterns\n",
    "\n",
    "4. Monitoring and Management:\n",
    "   - Set up budget alerts and spending limits\n",
    "   - Use Azure Cost Management + Billing\n",
    "   - Implement proper resource tagging\n",
    "   - Regular cost reviews and optimizations\n",
    "\n",
    "5. Service-Specific:\n",
    "   - Use Azure Functions for small, event-driven tasks\n",
    "   - Consider Azure Container Instances for short-running jobs\n",
    "   - Use Azure Batch for large-scale parallel processing\n",
    "\"\"\"\n",
    "    \n",
    "    cost_monitoring_commands = \"\"\"\n",
    "# Set up budget alerts\n",
    "az consumption budget create \\\n",
    "  --budget-name clustrix-monthly-budget \\\n",
    "  --amount 100 \\\n",
    "  --time-grain Monthly \\\n",
    "  --time-period-start 2025-01-01 \\\n",
    "  --time-period-end 2025-12-31\n",
    "\n",
    "# Get current costs\n",
    "az consumption usage list \\\n",
    "  --start-date 2025-01-01 \\\n",
    "  --end-date 2025-01-31\n",
    "\n",
    "# List resource costs\n",
    "az costmanagement query \\\n",
    "  --type Usage \\\n",
    "  --dataset-aggregation '{\"totalCost\":{\"name\":\"PreTaxCost\",\"function\":\"Sum\"}}' \\\n",
    "  --dataset-grouping name=ResourceGroup type=Dimension\n",
    "\"\"\"\n",
    "    \n",
    "    print(cost_tips)\n",
    "    print(\"\\nCost Monitoring Commands:\")\n",
    "    print(cost_monitoring_commands)\n",
    "    \n",
    "    return {\n",
    "        'recommendations': [\n",
    "            'Use Spot VMs for batch processing',\n",
    "            'Enable auto-shutdown for dev resources',\n",
    "            'Implement lifecycle policies for storage',\n",
    "            'Set up budget alerts',\n",
    "            'Regular cost reviews'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Example Spot VM configuration for cost savings\n",
    "def configure_spot_vm():\n",
    "    \"\"\"Example configuration for using Azure Spot VMs.\"\"\"\n",
    "    configure(\n",
    "        cluster_type=\"ssh\",\n",
    "        cluster_host=\"your-spot-vm-ip\",\n",
    "        username=\"azureuser\",\n",
    "        key_file=\"~/.ssh/id_rsa\",\n",
    "        remote_work_dir=\"/tmp/clustrix\",\n",
    "        # Spot VMs can be evicted, so use shorter timeouts\n",
    "        default_time=\"00:30:00\",\n",
    "        job_poll_interval=60,  # Check more frequently\n",
    "        cleanup_on_success=True  # Clean up quickly\n",
    "    )\n",
    "    print(\"Configured for Azure Spot VMs with appropriate timeouts.\")\n",
    "\n",
    "cost_guide = azure_cost_optimization_guide()\n",
    "print(\"\\nCost optimization guide generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-azure",
   "metadata": {},
   "source": [
    "## Resource Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup-azure-resources",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_azure_resources(resource_group='clustrix-tutorial-rg'):\n",
    "    \"\"\"\n",
    "    Clean up Azure resources to avoid ongoing charges.\n",
    "    \n",
    "    Args:\n",
    "        resource_group: Name of the resource group to clean up\n",
    "    \"\"\"\n",
    "    \n",
    "    cleanup_commands = f\"\"\"\n",
    "# List all resources in the resource group\n",
    "az resource list --resource-group {resource_group} --output table\n",
    "\n",
    "# Stop all VMs\n",
    "az vm deallocate --resource-group {resource_group} --name clustrix-vm-01\n",
    "\n",
    "# Delete specific resources (optional)\n",
    "az vm delete --resource-group {resource_group} --name clustrix-vm-01 --yes\n",
    "az disk delete --resource-group {resource_group} --name clustrix-vm-01_disk1_* --yes\n",
    "az network public-ip delete --resource-group {resource_group} --name clustrix-vm-01PublicIP\n",
    "\n",
    "# Delete the entire resource group (WARNING: This deletes everything!)\n",
    "az group delete --name {resource_group} --yes --no-wait\n",
    "\n",
    "# Verify deletion\n",
    "az group list --output table\n",
    "\"\"\"\n",
    "    \n",
    "    print(f\"Azure Resource Cleanup Commands for Resource Group: {resource_group}\")\n",
    "    print(cleanup_commands)\n",
    "    print(\"\\n⚠️  WARNING: The 'az group delete' command will permanently delete ALL resources in the group!\")\n",
    "    print(\"Review the resources first with 'az resource list' before proceeding.\")\n",
    "    \n",
    "    return {\n",
    "        'resource_group': resource_group,\n",
    "        'cleanup_commands': cleanup_commands\n",
    "    }\n",
    "\n",
    "cleanup_info = cleanup_azure_resources()\n",
    "print(\"\\nCleanup commands generated. Remember to clean up resources to avoid charges!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-azure-example",
   "metadata": {},
   "source": [
    "## Advanced Example: Distributed Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "image-processing-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cluster(cores=4, memory=\"8GB\", time=\"00:45:00\")\n",
    "def azure_image_processing_pipeline(storage_config, processing_params):\n",
    "    \"\"\"\n",
    "    Distributed image processing pipeline using Azure Blob Storage.\n",
    "    \"\"\"\n",
    "    from azure.storage.blob import BlobServiceClient\n",
    "    from azure.identity import DefaultAzureCredential\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    import io\n",
    "    import time\n",
    "    \n",
    "    # Connect to Azure Blob Storage\n",
    "    account_url = f\"https://{storage_config['account_name']}.blob.core.windows.net\"\n",
    "    credential = DefaultAzureCredential()\n",
    "    blob_service_client = BlobServiceClient(account_url=account_url, credential=credential)\n",
    "    \n",
    "    container_client = blob_service_client.get_container_client(storage_config['container'])\n",
    "    \n",
    "    processed_images = []\n",
    "    processing_stats = []\n",
    "    \n",
    "    # List images to process\n",
    "    blob_list = container_client.list_blobs(name_starts_with=storage_config['input_prefix'])\n",
    "    \n",
    "    for blob in blob_list:\n",
    "        if blob.name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                # Download image\n",
    "                blob_client = blob_service_client.get_blob_client(\n",
    "                    container=storage_config['container'], blob=blob.name\n",
    "                )\n",
    "                image_data = blob_client.download_blob().readall()\n",
    "                \n",
    "                # Process image\n",
    "                image = Image.open(io.BytesIO(image_data))\n",
    "                \n",
    "                # Apply processing operations\n",
    "                if processing_params.get('resize'):\n",
    "                    image = image.resize(processing_params['resize'])\n",
    "                \n",
    "                if processing_params.get('grayscale'):\n",
    "                    image = image.convert('L')\n",
    "                \n",
    "                if processing_params.get('rotate'):\n",
    "                    image = image.rotate(processing_params['rotate'])\n",
    "                \n",
    "                # Convert back to bytes\n",
    "                output_buffer = io.BytesIO()\n",
    "                image.save(output_buffer, format='PNG')\n",
    "                output_buffer.seek(0)\n",
    "                \n",
    "                # Upload processed image\n",
    "                output_blob_name = blob.name.replace(\n",
    "                    storage_config['input_prefix'], \n",
    "                    storage_config['output_prefix']\n",
    "                )\n",
    "                \n",
    "                output_blob_client = blob_service_client.get_blob_client(\n",
    "                    container=storage_config['container'], blob=output_blob_name\n",
    "                )\n",
    "                output_blob_client.upload_blob(output_buffer.getvalue(), overwrite=True)\n",
    "                \n",
    "                processing_time = time.time() - start_time\n",
    "                \n",
    "                processed_images.append(output_blob_name)\n",
    "                processing_stats.append({\n",
    "                    'input_blob': blob.name,\n",
    "                    'output_blob': output_blob_name,\n",
    "                    'processing_time': processing_time,\n",
    "                    'original_size': image.size,\n",
    "                    'processed_size': image.size\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {blob.name}: {e}\")\n",
    "    \n",
    "    return {\n",
    "        'processed_count': len(processed_images),\n",
    "        'total_processing_time': sum(stat['processing_time'] for stat in processing_stats),\n",
    "        'average_processing_time': np.mean([stat['processing_time'] for stat in processing_stats]) if processing_stats else 0,\n",
    "        'processed_images': processed_images[:10],  # First 10 for brevity\n",
    "        'processing_stats': processing_stats[:5]  # First 5 for brevity\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "# storage_config = {\n",
    "#     'account_name': 'yourstorageaccount',\n",
    "#     'container': 'images',\n",
    "#     'input_prefix': 'raw/',\n",
    "#     'output_prefix': 'processed/'\n",
    "# }\n",
    "# \n",
    "# processing_config = {\n",
    "#     'resize': (800, 600),\n",
    "#     'grayscale': True,\n",
    "#     'rotate': 0\n",
    "# }\n",
    "# \n",
    "# result = azure_image_processing_pipeline(storage_config, processing_config)\n",
    "# print(f\"Processed {result['processed_count']} images in {result['total_processing_time']:.2f} seconds\")\n",
    "\n",
    "print(\"Advanced image processing pipeline example defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "azure-summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial covered:\n",
    "\n",
    "1. **Setup**: Azure authentication and Clustrix installation\n",
    "2. **VM Integration**: Direct Azure VM configuration\n",
    "3. **Azure Batch**: Managed job scheduling\n",
    "4. **CycleCloud**: HPC-optimized clusters with SLURM\n",
    "5. **Blob Storage**: Data storage and retrieval\n",
    "6. **Azure ML**: Machine learning compute integration\n",
    "7. **Security**: Best practices for safe deployment\n",
    "8. **Cost Management**: Strategies to minimize expenses\n",
    "9. **Resource Management**: Proper cleanup procedures\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Set up your Azure credentials and test the basic configuration\n",
    "- Start with a simple VM for initial testing\n",
    "- Consider CycleCloud for production HPC workloads\n",
    "- Implement proper monitoring and cost controls\n",
    "- Explore Azure Spot VMs for cost-effective batch processing\n",
    "\n",
    "### Azure-Specific Advantages\n",
    "\n",
    "- **CycleCloud**: Best-in-class HPC cluster management\n",
    "- **Azure ML**: Integrated machine learning platform\n",
    "- **Hybrid Cloud**: Seamless integration with on-premises\n",
    "- **Enterprise Integration**: Active Directory and enterprise tools\n",
    "- **Compliance**: Strong compliance and security certifications\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Azure CycleCloud Documentation](https://docs.microsoft.com/en-us/azure/cyclecloud/)\n",
    "- [Azure Batch Documentation](https://docs.microsoft.com/en-us/azure/batch/)\n",
    "- [Azure Machine Learning Documentation](https://docs.microsoft.com/en-us/azure/machine-learning/)\n",
    "- [Azure HPC Documentation](https://docs.microsoft.com/en-us/azure/architecture/topics/high-performance-computing/)\n",
    "- [Clustrix Documentation](https://clustrix.readthedocs.io/)\n",
    "\n",
    "**Remember**: Always monitor your Azure costs and clean up resources when not in use!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}