{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ClustriX: Distributed Computing Framework Demo\n",
    "\n",
    "This notebook demonstrates how ClustriX enables seamless execution of Python functions on remote clusters using a simple `@cluster` decorator.\n",
    "\n",
    "## üìã Overview\n",
    "\n",
    "ClustriX is a Python framework that allows you to:\n",
    "- Execute functions on remote clusters (SLURM, PBS, SGE, Kubernetes, SSH)\n",
    "- Automatically parallelize loops across cluster nodes\n",
    "- Handle GPU detection and GPU-enabled package installation\n",
    "- Flatten nested functions for remote serialization\n",
    "- Manage remote environments automatically\n",
    "\n",
    "## üîß Configuration\n",
    "\n",
    "First, let's understand the configuration structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import yaml\nfrom clustrix.config import ClusterConfig\n\n# Load the actual ndoli configuration files\nprint(\"üìã Loading Actual ndoli Configuration Files:\")\nprint(\"=\" * 60)\n\n# Load the standalone ndoli config file\nwith open('ndoli_config.yml', 'r') as f:\n    ndoli_standalone_config = yaml.safe_load(f)\n\nprint(\"üîß Standalone ndoli_config.yml:\")\nprint(yaml.dump(ndoli_standalone_config, default_flow_style=False, indent=2))\n\nprint(\"\\n\" + \"=\" * 60)\n\n# Load the main clustrix.yml file\nwith open('clustrix.yml', 'r') as f:\n    main_config = yaml.safe_load(f)\n\nprint(\"üîß Main clustrix.yml (Ndoli Cluster section):\")\nndoli_main_config = main_config.get('Ndoli Cluster', {})\nprint(yaml.dump(ndoli_main_config, default_flow_style=False, indent=2))\n\nprint(\"\\n\" + \"=\" * 60)\n\n# Create a working configuration combining both approaches\n# Use the standalone config as the base since it has more complete settings\nndoli_config = ndoli_standalone_config.copy()\n\n# Add some additional settings for the demo\nndoli_config.update({\n    # Advanced features for demo\n    \"auto_parallel\": True,\n    \"use_two_venv\": True,\n    \"gpu_detection_enabled\": True,\n    \"auto_gpu_packages\": True,\n    \"cleanup_remote_files\": True,\n    \n    # VENV setup\n    \"venv_setup_timeout\": 300,\n    \"conda_env_name\": \"clustrix_env\",\n    \"use_conda\": True,\n    \n    # GPU settings\n    \"cuda_version_preference\": \"11.8\",\n    \"gpu_memory_fraction\": 0.9,\n    \"prefer_gpu_execution\": True\n})\n\nprint(\"üöÄ Working Configuration for Demo:\")\nprint(\"(Combined from actual config files with demo enhancements)\")\nprint(yaml.dump(ndoli_config, default_flow_style=False, indent=2))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ The @cluster Decorator\n",
    "\n",
    "The `@cluster` decorator is the main interface for remote execution. Here's how it works:\n",
    "\n",
    "### Basic Usage\n",
    "```python\n",
    "@cluster(cores=8, memory=\"16GB\", time=\"02:00:00\")\n",
    "def my_function(data):\n",
    "    # Your computation here\n",
    "    return result\n",
    "```\n",
    "\n",
    "### What the Decorator Does\n",
    "1. **Serializes** the function and its dependencies using cloudpickle/dill\n",
    "2. **Uploads** the serialized data to the remote cluster\n",
    "3. **Creates** a conda/venv environment matching your local environment\n",
    "4. **Generates** and submits a job script (SLURM, PBS, etc.)\n",
    "5. **Monitors** job execution and downloads results\n",
    "6. **Cleans up** remote files (optional)\n",
    "\n",
    "### Advanced Features\n",
    "- **Loop Parallelization**: Automatically detects and parallelizes `for` loops\n",
    "- **Function Flattening**: Converts nested functions to flat code for serialization\n",
    "- **GPU Detection**: Automatically detects and configures GPU resources\n",
    "- **Environment Management**: Two-VENV architecture for optimal performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a ClusterConfig object\n",
    "config = ClusterConfig(**ndoli_config)\n",
    "\n",
    "print(\"üîß ClusterConfig Object:\")\n",
    "print(f\"  Cluster Type: {config.cluster_type}\")\n",
    "print(f\"  Cluster Host: {config.cluster_host}\")\n",
    "print(f\"  Username: {config.username}\")\n",
    "print(f\"  Remote Work Dir: {config.remote_work_dir}\")\n",
    "print(f\"  Auto Parallel: {config.auto_parallel}\")\n",
    "print(f\"  GPU Detection: {config.gpu_detection_enabled}\")\n",
    "print(f\"  Two VENV Setup: {config.use_two_venv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Example 1: Simple Remote Execution\n",
    "\n",
    "Let's start with a simple function that executes on the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustrix import cluster\n",
    "import time\n",
    "\n",
    "@cluster(**ndoli_config)\n",
    "def simple_cluster_computation(n=1000):\n",
    "    \"\"\"Simple computation that runs on the cluster.\"\"\"\n",
    "    import math\n",
    "    import socket\n",
    "    import os\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Perform some computation\n",
    "    result = sum(math.sqrt(i) for i in range(n))\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    return {\n",
    "        \"result\": result,\n",
    "        \"computation_time\": end_time - start_time,\n",
    "        \"hostname\": socket.gethostname(),\n",
    "        \"process_id\": os.getpid(),\n",
    "        \"working_directory\": os.getcwd(),\n",
    "        \"python_version\": os.sys.version,\n",
    "        \"input_size\": n\n",
    "    }\n",
    "\n",
    "print(\"üöÄ Running simple computation on ndoli cluster...\")\n",
    "print(\"This will submit a job to the SLURM scheduler and wait for results.\")\n",
    "print(\"Please be patient - this may take a few minutes.\")\n",
    "\n",
    "# Execute the function\n",
    "try:\n",
    "    result = simple_cluster_computation(500)\n",
    "    \n",
    "    print(\"\\n‚úÖ Computation completed successfully!\")\n",
    "    print(f\"üìä Result: {result['result']:.2f}\")\n",
    "    print(f\"‚è±Ô∏è  Computation time: {result['computation_time']:.4f} seconds\")\n",
    "    print(f\"üñ•Ô∏è  Executed on: {result['hostname']}\")\n",
    "    print(f\"üî¢ Process ID: {result['process_id']}\")\n",
    "    print(f\"üìÅ Working directory: {result['working_directory']}\")\n",
    "    print(f\"üêç Python version: {result['python_version'].split()[0]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during execution: {e}\")\n",
    "    print(\"This might be due to SSH connection issues or cluster unavailability.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Example 2: Loop Parallelization\n",
    "\n",
    "ClustriX can automatically detect and parallelize loops across cluster nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "@cluster(\n    cluster_type=\"slurm\",\n    cluster_host=\"ndoli.dartmouth.edu\",\n    username=\"f002d6b\",\n    cores=8,  # Request 8 cores for parallelization\n    memory=\"16GB\",\n    time=\"01:00:00\",\n    remote_work_dir=\"/dartfs-hpc/rc/home/b/f002d6b/clustrix_parallel\",\n    auto_parallel=True,  # Enable automatic loop parallelization\n    use_env_password=True,\n    password_env_var=\"CLUSTRIX_PASSWORD\"\n)\ndef parallel_computation(data_size=100):\n    \"\"\"Function with a loop that can be parallelized.\"\"\"\n    import math\n    import time\n    import socket\n    \n    start_time = time.time()\n    \n    # This loop will be automatically parallelized across cores\n    results = []\n    for i in range(data_size):  # ClustriX detects this loop\n        # Simulate some computation\n        value = math.sqrt(i) * math.sin(i) * math.cos(i)\n        results.append(value)\n    \n    end_time = time.time()\n    \n    return {\n        \"results_count\": len(results),\n        \"sum_results\": sum(results),\n        \"mean_result\": sum(results) / len(results) if results else 0,\n        \"computation_time\": end_time - start_time,\n        \"hostname\": socket.gethostname(),\n        \"data_size\": data_size,\n        \"message\": \"Loop was automatically parallelized!\"\n    }\n\nprint(\"üîÑ Running parallel computation on ndoli cluster...\")\nprint(\"ClustriX will detect the loop and parallelize it across 8 cores.\")\n\ntry:\n    result = parallel_computation(50)\n    \n    print(\"\\n‚úÖ Parallel computation completed!\")\n    print(f\"üìä Processed {result['results_count']} items\")\n    print(f\"üìà Sum of results: {result['sum_results']:.4f}\")\n    print(f\"üìä Mean result: {result['mean_result']:.4f}\")\n    print(f\"‚è±Ô∏è  Total time: {result['computation_time']:.4f} seconds\")\n    print(f\"üñ•Ô∏è  Executed on: {result['hostname']}\")\n    print(f\"‚ú® {result['message']}\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Error during parallel execution: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Example 3: Function Flattening (Complex Functions)\n",
    "\n",
    "ClustriX can handle complex functions with nested functions by automatically \"flattening\" them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clustrix.function_flattening import analyze_function_complexity\n",
    "\n",
    "@cluster(**ndoli_config)\n",
    "def complex_nested_function(data_size=50):\n",
    "    \"\"\"Function with nested functions that requires flattening.\"\"\"\n",
    "    import random\n",
    "    import socket\n",
    "    import time\n",
    "    \n",
    "    def generate_random_data(size):\n",
    "        \"\"\"Generate random data for processing.\"\"\"\n",
    "        return [random.random() for _ in range(size)]\n",
    "    \n",
    "    def process_data_chunk(chunk):\n",
    "        \"\"\"Process a chunk of data.\"\"\"\n",
    "        return sum(x * x for x in chunk)\n",
    "    \n",
    "    def analyze_results(processed_chunks):\n",
    "        \"\"\"Analyze the processed results.\"\"\"\n",
    "        if not processed_chunks:\n",
    "            return {\"count\": 0, \"sum\": 0, \"mean\": 0}\n",
    "        \n",
    "        return {\n",
    "            \"count\": len(processed_chunks),\n",
    "            \"sum\": sum(processed_chunks),\n",
    "            \"mean\": sum(processed_chunks) / len(processed_chunks),\n",
    "            \"max\": max(processed_chunks),\n",
    "            \"min\": min(processed_chunks)\n",
    "        }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Main computation using nested functions\n",
    "    raw_data = generate_random_data(data_size)\n",
    "    \n",
    "    # Split into chunks\n",
    "    chunk_size = 10\n",
    "    chunks = [raw_data[i:i+chunk_size] for i in range(0, len(raw_data), chunk_size)]\n",
    "    \n",
    "    # Process each chunk\n",
    "    processed = [process_data_chunk(chunk) for chunk in chunks]\n",
    "    \n",
    "    # Analyze results\n",
    "    analysis = analyze_results(processed)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    return {\n",
    "        \"data_size\": data_size,\n",
    "        \"chunks_processed\": len(chunks),\n",
    "        \"analysis\": analysis,\n",
    "        \"computation_time\": end_time - start_time,\n",
    "        \"hostname\": socket.gethostname(),\n",
    "        \"flattening_message\": \"Nested functions were automatically flattened for remote execution!\"\n",
    "    }\n",
    "\n",
    "# First, let's analyze the function complexity\n",
    "print(\"üß† Analyzing function complexity...\")\n",
    "complexity = analyze_function_complexity(complex_nested_function)\n",
    "print(f\"üìä Function complexity analysis: {complexity}\")\n",
    "\n",
    "if complexity.get('is_complex', False):\n",
    "    print(\"üîß This function is complex and will be automatically flattened!\")\n",
    "    print(f\"üìà Complexity score: {complexity.get('complexity_score', 0)}\")\n",
    "    print(f\"üî¢ Nested functions: {complexity.get('nested_functions', 0)}\")\n",
    "    print(f\"üìè Line count: {complexity.get('line_count', 0)}\")\nelse:\n",
    "    print(\"‚úÖ Function is simple and doesn't require flattening.\")\n",
    "\n",
    "print(\"\\nüöÄ Running complex function on ndoli cluster...\")\n",
    "try:\n",
    "    result = complex_nested_function(30)\n",
    "    \n",
    "    print(\"\\n‚úÖ Complex function executed successfully!\")\n",
    "    print(f\"üìä Data size: {result['data_size']}\")\n",
    "    print(f\"üì¶ Chunks processed: {result['chunks_processed']}\")\n",
    "    print(f\"üìà Analysis results:\")\n",
    "    for key, value in result['analysis'].items():\n",
    "        print(f\"   {key}: {value}\")\n",
    "    print(f\"‚è±Ô∏è  Computation time: {result['computation_time']:.4f} seconds\")\n",
    "    print(f\"üñ•Ô∏è  Executed on: {result['hostname']}\")\n",
    "    print(f\"‚ú® {result['flattening_message']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during complex execution: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéÆ Example 4: GPU Detection and Simulation\n",
    "\n",
    "ClustriX can detect GPU capabilities and automatically install GPU-enabled packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "@cluster(\n    cluster_type=\"slurm\",\n    cluster_host=\"ndoli.dartmouth.edu\",\n    username=\"f002d6b\",\n    cores=4,\n    memory=\"8GB\",\n    gpu_detection_enabled=True,\n    auto_gpu_packages=True,\n    remote_work_dir=\"/dartfs-hpc/rc/home/b/f002d6b/clustrix_gpu\",\n    use_env_password=True,\n    password_env_var=\"CLUSTRIX_PASSWORD\"\n)\ndef gpu_detection_demo():\n    \"\"\"Demonstrate GPU detection and simulation.\"\"\"\n    import subprocess\n    import socket\n    import os\n    import importlib.util\n    import sys\n    \n    def check_gpu_availability():\n        \"\"\"Check if GPU is available using multiple methods.\"\"\"\n        gpu_info = {\n            \"nvidia_smi\": False,\n            \"cuda_available\": False,\n            \"gpu_devices\": []\n        }\n        \n        # Check nvidia-smi\n        try:\n            result = subprocess.run(\n                [\"nvidia-smi\", \"--query-gpu=name,memory.total\", \"--format=csv,noheader\"],\n                capture_output=True, text=True, timeout=10\n            )\n            if result.returncode == 0:\n                gpu_info[\"nvidia_smi\"] = True\n                gpu_info[\"gpu_devices\"] = result.stdout.strip().split('\\n')\n        except:\n            pass\n        \n        # Check CUDA\n        try:\n            result = subprocess.run(\n                [\"nvcc\", \"--version\"], capture_output=True, text=True, timeout=5\n            )\n            if result.returncode == 0:\n                gpu_info[\"cuda_available\"] = True\n        except:\n            pass\n        \n        return gpu_info\n    \n    def check_gpu_packages():\n        \"\"\"Check for GPU-enabled packages.\"\"\"\n        gpu_packages = [\"torch\", \"tensorflow\", \"cupy\", \"jax\"]\n        package_status = {}\n        \n        for pkg in gpu_packages:\n            try:\n                spec = importlib.util.find_spec(pkg)\n                package_status[pkg] = spec is not None\n            except ImportError:\n                package_status[pkg] = False\n        \n        return package_status\n    \n    def simulate_gpu_computation():\n        \"\"\"Simulate GPU computation (mock).\"\"\"\n        import random\n        import time\n        \n        start_time = time.time()\n        \n        # Simulate matrix multiplication\n        matrix_size = 100\n        result = 0\n        for i in range(matrix_size):\n            for j in range(matrix_size):\n                result += random.random() * random.random()\n        \n        end_time = time.time()\n        \n        return {\n            \"matrix_size\": matrix_size,\n            \"result\": result,\n            \"computation_time\": end_time - start_time\n        }\n    \n    # Main execution\n    gpu_info = check_gpu_availability()\n    packages = check_gpu_packages()\n    computation = simulate_gpu_computation()\n    \n    return {\n        \"hostname\": socket.gethostname(),\n        \"python_version\": sys.version,\n        \"gpu_detection\": gpu_info,\n        \"gpu_packages\": packages,\n        \"gpu_computation\": computation,\n        \"system_info\": {\n            \"os\": os.name,\n            \"cwd\": os.getcwd(),\n            \"pid\": os.getpid()\n        }\n    }\n\nprint(\"üéÆ Running GPU detection demo on ndoli cluster...\")\nprint(\"This will test GPU detection and package availability.\")\n\ntry:\n    result = gpu_detection_demo()\n    \n    print(\"\\n‚úÖ GPU detection demo completed!\")\n    print(f\"üñ•Ô∏è  Executed on: {result['hostname']}\")\n    print(f\"üêç Python version: {result['python_version'].split()[0]}\")\n    \n    print(\"\\nüéÆ GPU Detection Results:\")\n    gpu_info = result['gpu_detection']\n    print(f\"   nvidia-smi available: {gpu_info['nvidia_smi']}\")\n    print(f\"   CUDA available: {gpu_info['cuda_available']}\")\n    if gpu_info['gpu_devices']:\n        print(f\"   GPU devices: {gpu_info['gpu_devices']}\")\n    \n    print(\"\\nüì¶ GPU Package Status:\")\n    for pkg, available in result['gpu_packages'].items():\n        status = \"‚úÖ\" if available else \"‚ùå\"\n        print(f\"   {pkg}: {status}\")\n    \n    print(\"\\nüöÄ GPU Computation Simulation:\")\n    comp = result['gpu_computation']\n    print(f\"   Matrix size: {comp['matrix_size']}x{comp['matrix_size']}\")\n    print(f\"   Result: {comp['result']:.2f}\")\n    print(f\"   Computation time: {comp['computation_time']:.4f}s\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Error during GPU detection: {e}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Example 5: Comparing Local vs Remote Execution\n",
    "\n",
    "Let's compare the same computation running locally vs on the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import socket\n",
    "\n",
    "def benchmark_computation(n=10000):\n",
    "    \"\"\"Benchmark computation for comparison.\"\"\"\n",
    "    import math\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Computational task\n",
    "    result = 0\n",
    "    for i in range(n):\n",
    "        result += math.sqrt(i) * math.sin(i / 100) * math.cos(i / 200)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    return {\n",
    "        \"result\": result,\n",
    "        \"computation_time\": end_time - start_time,\n",
    "        \"hostname\": socket.gethostname(),\n",
    "        \"iterations\": n\n",
    "    }\n",
    "\n",
    "# Create cluster version\n",
    "@cluster(**ndoli_config)\n",
    "def benchmark_computation_cluster(n=10000):\n",
    "    \"\"\"Same computation but on cluster.\"\"\"\n",
    "    import math\n",
    "    import time\n",
    "    import socket\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Identical computational task\n",
    "    result = 0\n",
    "    for i in range(n):\n",
    "        result += math.sqrt(i) * math.sin(i / 100) * math.cos(i / 200)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    return {\n",
    "        \"result\": result,\n",
    "        \"computation_time\": end_time - start_time,\n",
    "        \"hostname\": socket.gethostname(),\n",
    "        \"iterations\": n\n",
    "    }\n",
    "\n",
    "# Run local computation\n",
    "print(\"üñ•Ô∏è  Running computation locally...\")\n",
    "local_result = benchmark_computation(5000)\n",
    "print(f\"‚úÖ Local computation completed in {local_result['computation_time']:.4f}s\")\n",
    "print(f\"   Result: {local_result['result']:.2f}\")\n",
    "print(f\"   Hostname: {local_result['hostname']}\")\n",
    "\n",
    "# Run cluster computation\n",
    "print(\"\\nüöÄ Running computation on ndoli cluster...\")\n",
    "try:\n",
    "    cluster_result = benchmark_computation_cluster(5000)\n",
    "    print(f\"‚úÖ Cluster computation completed in {cluster_result['computation_time']:.4f}s\")\n",
    "    print(f\"   Result: {cluster_result['result']:.2f}\")\n",
    "    print(f\"   Hostname: {cluster_result['hostname']}\")\n",
    "    \n",
    "    # Compare results\n",
    "    print(\"\\nüìä Comparison:\")\n",
    "    print(f\"   Local time: {local_result['computation_time']:.4f}s\")\n",
    "    print(f\"   Cluster time: {cluster_result['computation_time']:.4f}s\")\n",
    "    \n",
    "    if abs(local_result['result'] - cluster_result['result']) < 0.01:\n",
    "        print(\"   ‚úÖ Results match - computation is consistent!\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  Results differ - may be due to different random seeds\")\n",
    "        \n",
    "    if local_result['hostname'] != cluster_result['hostname']:\n",
    "        print(\"   ‚úÖ Cluster execution verified - different hostnames!\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  Both executed on same host - cluster execution may have failed\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Cluster computation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Advanced Configuration Options\n",
    "\n",
    "ClustriX offers many advanced configuration options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Advanced configuration example based on actual ndoli setup\nadvanced_config = {\n    # Basic cluster settings (from actual config)\n    \"cluster_type\": \"slurm\",\n    \"cluster_host\": \"ndoli.dartmouth.edu\",\n    \"username\": \"f002d6b\",\n    \"remote_work_dir\": \"/dartfs-hpc/rc/home/b/f002d6b/clustrix_advanced\",\n    \"python_executable\": \"python3\",\n    \n    # Authentication (environment variables only)\n    \"use_env_password\": True,\n    \"password_env_var\": \"CLUSTRIX_PASSWORD\",\n    \n    # Resource management (from actual config)\n    \"default_cores\": 2,\n    \"default_memory\": \"4GB\",\n    \"default_time\": \"00:10:00\",\n    \"default_partition\": \"standard\",\n    \n    # Environment setup (from actual config)\n    \"module_loads\": [\"python\"],\n    \"environment_variables\": {\"OMP_NUM_THREADS\": \"1\"},\n    \"pre_execution_commands\": [\n        \"export PATH=/usr/bin:$PATH\",\n        \"which python3 || echo 'Python3 not found in PATH'\",\n        \"module list\"\n    ],\n    \n    # Advanced features for production\n    \"auto_parallel\": True,\n    \"auto_gpu_parallel\": True,\n    \"max_parallel_jobs\": 10,\n    \n    # Environment management\n    \"use_two_venv\": True,\n    \"venv_setup_timeout\": 600,\n    \"use_conda\": True,\n    \"conda_env_name\": \"clustrix_gpu\",\n    \n    # GPU settings\n    \"gpu_detection_enabled\": True,\n    \"auto_gpu_packages\": True,\n    \"cuda_version_preference\": \"11.8\",\n    \"gpu_memory_fraction\": 0.8,\n    \"prefer_gpu_execution\": True,\n    \"rapids_ecosystem\": True,\n    \n    # File management\n    \"cleanup_remote_files\": True,\n    \"preserve_logs\": True,\n    \"log_level\": \"INFO\",\n    \n    # SSH settings\n    \"ssh_timeout\": 30,\n    \"ssh_port\": 22,\n    \n    # Job monitoring\n    \"job_poll_interval\": 5,\n    \"max_job_runtime\": 7200,  # 2 hours\n    \"retry_on_failure\": True,\n    \"max_retries\": 3\n}\n\nprint(\"üîß Advanced Configuration Options (Based on Actual ndoli Setup):\")\nprint(\"=\" * 60)\n\n# Group settings by category\ncategories = {\n    \"üèóÔ∏è  Basic Settings\": [\"cluster_type\", \"cluster_host\", \"username\", \"remote_work_dir\", \"python_executable\"],\n    \"üîê Authentication\": [\"use_env_password\", \"password_env_var\"],\n    \"üíæ Resource Management\": [\"default_cores\", \"default_memory\", \"default_time\", \"default_partition\"],\n    \"üåç Environment Setup\": [\"module_loads\", \"environment_variables\", \"pre_execution_commands\"],\n    \"‚ö° Parallelization\": [\"auto_parallel\", \"auto_gpu_parallel\", \"max_parallel_jobs\"],\n    \"üêç Environment Management\": [\"use_two_venv\", \"use_conda\", \"conda_env_name\", \"venv_setup_timeout\"],\n    \"üéÆ GPU Settings\": [\"gpu_detection_enabled\", \"auto_gpu_packages\", \"cuda_version_preference\", \"gpu_memory_fraction\"],\n    \"üìÅ File Management\": [\"cleanup_remote_files\", \"preserve_logs\", \"log_level\"],\n    \"üîí SSH Settings\": [\"ssh_timeout\", \"ssh_port\"],\n    \"‚è∞ Job Monitoring\": [\"job_poll_interval\", \"max_job_runtime\", \"retry_on_failure\", \"max_retries\"]\n}\n\nfor category, keys in categories.items():\n    print(f\"\\n{category}:\")\n    for key in keys:\n        if key in advanced_config:\n            value = advanced_config[key]\n            if isinstance(value, list):\n                print(f\"  {key}: {value}\")\n            elif isinstance(value, dict):\n                print(f\"  {key}: {value}\")\n            else:\n                print(f\"  {key}: {value}\")\n\nprint(\"\\nüí° Tips for ndoli.dartmouth.edu:\")\nprint(\"  - Use environment variables for secure authentication\")\nprint(\"  - Set CLUSTRIX_PASSWORD environment variable for SSH authentication\")\nprint(\"  - Load 'python' module for Python 3 access\")\nprint(\"  - Set OMP_NUM_THREADS=1 for optimal performance\")\nprint(\"  - Use 'standard' partition for regular jobs\")\nprint(\"  - Default time limit is 10 minutes - adjust as needed\")\nprint(\"  - Remote work directory uses dartfs-hpc for persistence\")\nprint(\"  - Set cleanup_remote_files=False for debugging\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Summary\n",
    "\n",
    "This notebook demonstrated the key features of ClustriX:\n",
    "\n",
    "### ‚úÖ **Core Features**\n",
    "- **Simple `@cluster` decorator** for remote execution\n",
    "- **Automatic loop parallelization** across cluster nodes\n",
    "- **Function flattening** for complex nested functions\n",
    "- **GPU detection** and automatic GPU package installation\n",
    "- **Environment management** with two-VENV architecture\n",
    "- **Flexible configuration** for different cluster types\n",
    "\n",
    "### üöÄ **Benefits**\n",
    "- **Easy to use**: Just add `@cluster` to any function\n",
    "- **Automatic optimization**: Loop parallelization and GPU detection\n",
    "- **Robust**: Handles complex functions and environments\n",
    "- **Flexible**: Works with SLURM, PBS, SGE, SSH, Kubernetes\n",
    "- **Efficient**: Two-VENV architecture for optimal performance\n",
    "\n",
    "### üîß **Next Steps**\n",
    "1. **Set up SSH keys** for passwordless authentication\n",
    "2. **Configure cluster-specific settings** in `clustrix.yml`\n",
    "3. **Test simple functions** first, then move to complex ones\n",
    "4. **Monitor job logs** for debugging and optimization\n",
    "5. **Experiment with parallelization** for performance gains\n",
    "\n",
    "Happy cluster computing! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}