<!DOCTYPE html>
<html class="no-js" lang="en" data-content_root="../">
<head>
    <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    
        <title>Lambda Cloud Tutorial &mdash; Clustrix Documentation</title>
    
    <link rel="stylesheet" type="text/css" href="../_static/dist/fontawesome.css" />
      <link rel="stylesheet" type="text/css" href="../_static/dist/theme.css?v=310cf088" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=554e4187" />
            <link rel="index" title="Index" href="../genindex.html" />
            <link rel="search" title="Search" href="../search.html" />
            <link rel="top" title="Clustrix Documentation" href="#" />
            <link rel="next" title="Cloud Cost Monitoring and Optimization" href="cost_monitoring_tutorial.html" />
            <link rel="prev" title="HuggingFace Spaces Tutorial" href="huggingface_spaces_tutorial.html" />
    </head>
<body>
    <script type="text/javascript" src="../_static/dist/blocking.js"></script>
    <header class="container-fluid bg-primary">
        <a class="btn btn-sm btn-light skip-to-content-link" href="#main">Skip to content</a>
        <div class="container-fluid">
            <div class="navbar navbar-expand-lg navbar-dark font-weight-bold">
                    <a href="../index.html"
                        title="Wagtail"
                        class="logo navbar-brand"
                    >
                        <img src="../_static/img/wagtail-logo-circle.svg" width="45" height="59" alt="Wagtail"
                            class="logo-img"
                        />
                        Clustrix
                    </a>
                
                
                <button class="navbar-toggler btn btn-primary d-lg-none" type="button" data-toggle="collapse" data-target="#collapseSidebar" aria-expanded="false" aria-controls="collapseExample">
                    <span class="navbar-toggler-icon"></span>
                    <span class="sr-only">menu</span>
                </button>
            </div>
        </div>
    </header>
    <div class="container-fluid">
        <div class="row">
            <aside class="col-12 col-lg-3 sidebar-container">
                <div id="collapseSidebar" class="collapse sticky-top d-lg-block pt-5 pr-lg-4">
<div id="searchbox" class="searchbox mb-6 px-1" role="search">
    <form id="search-form" action="../search.html" autocomplete="off" method="get" role="search">
        <div class="input-group">
            <div class="input-group-prepend">
                <div class="input-group-text border-right-0 bg-white py-3 pl-3 pr-2"><span class="fas fa-search"></span></div>
            </div>
            <input class="form-control py-3 pr-3 pl-1 h-100 border-left-0" type="search" name="q" placeholder="Search documentation" aria-label="Search documentation" id="searchinput" />
        </div>
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
    </form>
</div><div class="site-toc">
    <nav class="toc mt-3" aria-label="Main menu">
        <p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ssh_setup.html">SSH Key Setup for Remote Clusters</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/slurm_tutorial.html">SLURM Cluster Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/pbs_tutorial.html">PBS/Torque Cluster Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/kubernetes_tutorial.html">Kubernetes Cluster Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Interactive Notebooks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cluster_config_example.html">Clustrix Configuration Manager Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="complete_api_demo.html">Complete Clustrix API Demonstration</a></li>
<li class="toctree-l1"><a class="reference internal" href="slurm_tutorial.html">SLURM Cluster Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="pbs_tutorial.html">PBS/Torque Cluster Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="sge_tutorial.html">SGE (Sun Grid Engine) Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="kubernetes_tutorial.html">Kubernetes Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="ssh_tutorial.html">SSH Remote Execution Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="basic_usage.html">Clustrix Basic Usage Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Cloud Platform Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="aws_cloud_tutorial.html">Amazon Web Services (AWS) Cloud Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="azure_cloud_tutorial.html">Microsoft Azure Cloud Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="gcp_cloud_tutorial.html">Google Cloud Platform (GCP) Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="huggingface_spaces_tutorial.html">HuggingFace Spaces Tutorial</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Lambda Cloud Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="cost_monitoring_tutorial.html">Cloud Cost Monitoring and Optimization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/decorator.html">Decorator API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/config.html">Configuration API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/notebook_magic.html">Notebook Magic Commands</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/cost_monitoring.html">Cost Monitoring</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/local_executor.html">Local Executor API</a></li>
</ul>

    </nav>
    <template data-toggle-item-template>
        <button class="btn btn-sm btn-link toctree-expand" type="button">
            <span class="sr-only">Toggle menu contents</span>
        </button>
    </template>
</div>
                    <div class="d-lg-none border-bottom">
                        
                    </div>
                </div>
            </aside>
            <div class="col-12 col-lg-9 pt-5">
                <header class="row align-items-baseline">
                    <div class="col">
                        <nav aria-label="breadcrumb">
    <ol class="breadcrumb m-0 p-0 bg-transparent">
        <li class="breadcrumb-item"><a href="../index.html">Docs</a></li>
        <li class="breadcrumb-item active" aria-current="page">Lambda Cloud Tutorial</li>
    </ol>
</nav>
                    </div>
                    <div class="col-sm-12 col-lg-auto mt-3 mt-lg-3">
                        <noscript>
                            <p>JavaScript is required to toggle light/dark mode..</p>
                        </noscript>
                        <button id="wagtail-theme" class="btn btn-sm btn-light text-decoration-none" type="button">
                            <span class="dark-only"><i class="fas fa-sun"></i> Light mode</span>
                            <span class="light-only"><i class="fas fa-moon"></i> Dark mode</span>
                        </button>
    <a class="btn btn-sm btn-light text-decoration-none" href="https://github.com/ContextLab/clustrix/blob/master/docs/source/notebooks/lambda_cloud_tutorial.ipynb" rel="nofollow">
        <span class="btn-icon"><span class="fab fa-github"></span></span>
        <span class="btn-text">Edit on GitHub</span>
    </a>
    <a class="btn btn-sm btn-light text-decoration-none" href="../_sources/notebooks/lambda_cloud_tutorial.ipynb.txt" rel="nofollow">
        <span class="btn-icon"><span class="fas fa-code"></span></span>
        <span class="btn-text">View source</span>
    </a>
                        
                    </div>
                </header>
                <div class="row" >
                    <div class="col-12">
                        <hr class="w-100 my-4">
                    </div>
                </div>
                <div class="row">
                    <div class="col-12 col-lg-9 order-last order-lg-first rst-content">
                        <main role="main" id="main">
    <section id="Lambda-Cloud-Tutorial">
<h1>Lambda Cloud Tutorial<a class="headerlink" href="#Lambda-Cloud-Tutorial" title="Link to this heading">¶</a></h1>
<p>This tutorial demonstrates how to use Clustrix with Lambda Cloud for high-performance GPU computing and distributed machine learning.</p>
<p><a class="reference external" href="https://colab.research.google.com/github/ContextLab/clustrix/blob/master/docs/source/notebooks/lambda_cloud_tutorial.ipynb"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<section id="Overview">
<h2>Overview<a class="headerlink" href="#Overview" title="Link to this heading">¶</a></h2>
<p>Lambda Cloud specializes in GPU cloud computing and integrates well with Clustrix for ML workloads:</p>
<ul class="simple">
<li><p><strong>GPU-Optimized Instances</strong>: High-performance NVIDIA GPUs (A100, H100, RTX)</p></li>
<li><p><strong>Cost-Effective</strong>: Competitive pricing for GPU computing</p></li>
<li><p><strong>Simple Management</strong>: Easy instance launching and management</p></li>
<li><p><strong>Pre-configured Environments</strong>: ML-ready software stacks</p></li>
<li><p><strong>High-Speed Networking</strong>: InfiniBand for multi-GPU communications</p></li>
<li><p><strong>Persistent Storage</strong>: Fast NVMe and network storage options</p></li>
<li><p><strong>SSH Access</strong>: Direct access for Clustrix integration</p></li>
<li><p><strong>On-Demand and Reserved</strong>: Flexible pricing models</p></li>
</ul>
</section>
<section id="Prerequisites">
<h2>Prerequisites<a class="headerlink" href="#Prerequisites" title="Link to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p>Lambda Cloud account with GPU credits</p></li>
<li><p>SSH key pair for instance access</p></li>
<li><p>Lambda Cloud API key (optional)</p></li>
<li><p>Basic understanding of GPU computing</p></li>
</ol>
</section>
<section id="Installation-and-Setup">
<h2>Installation and Setup<a class="headerlink" href="#Installation-and-Setup" title="Link to this heading">¶</a></h2>
<p>Install Clustrix with Lambda Cloud dependencies:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install Clustrix with GPU and Lambda Cloud support</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>clustrix<span class="w"> </span>torch<span class="w"> </span>torchvision<span class="w"> </span>transformers<span class="w"> </span>datasets<span class="w"> </span>accelerate

<span class="c1"># Import required libraries</span>
<span class="kn">import</span> <span class="nn">clustrix</span>
<span class="kn">from</span> <span class="nn">clustrix</span> <span class="kn">import</span> <span class="n">cluster</span><span class="p">,</span> <span class="n">configure</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">os</span>
</pre></div>
</div>
</div>
</section>
<section id="Lambda-Cloud-Authentication-and-Setup">
<h2>Lambda Cloud Authentication and Setup<a class="headerlink" href="#Lambda-Cloud-Authentication-and-Setup" title="Link to this heading">¶</a></h2>
<section id="Option-1:-Web-Console-Setup">
<h3>Option 1: Web Console Setup<a class="headerlink" href="#Option-1:-Web-Console-Setup" title="Link to this heading">¶</a></h3>
</section>
<section id="Lambda-Cloud-Web-Console-Setup">
<h3>Lambda Cloud Web Console Setup<a class="headerlink" href="#Lambda-Cloud-Web-Console-Setup" title="Link to this heading">¶</a></h3>
<ol class="arabic simple">
<li><p><strong>Create Account:</strong></p>
<ul class="simple">
<li><p>Visit <a class="reference external" href="https://lambdalabs.com/service/gpu-cloud">https://lambdalabs.com/service/gpu-cloud</a></p></li>
<li><p>Sign up and verify your account</p></li>
<li><p>Add billing information and credits</p></li>
</ul>
</li>
<li><p><strong>Add SSH Key:</strong></p>
<ul class="simple">
<li><p>Go to <a class="reference external" href="https://cloud.lambdalabs.com/ssh-keys">https://cloud.lambdalabs.com/ssh-keys</a></p></li>
<li><p>Click “Add SSH Key”</p></li>
<li><p>Paste your public key (cat ~/.ssh/id_rsa.pub)</p></li>
<li><p>Give it a descriptive name</p></li>
</ul>
</li>
<li><p><strong>Launch Instance:</strong></p>
<ul class="simple">
<li><p>Go to <a class="reference external" href="https://cloud.lambdalabs.com/instances">https://cloud.lambdalabs.com/instances</a></p></li>
<li><p>Click “Launch instance”</p></li>
<li><p>Select instance type (A100, H100, RTX 6000 Ada, etc.)</p></li>
<li><p>Choose region (closest to you for best performance)</p></li>
<li><p>Select your SSH key</p></li>
<li><p>Launch the instance</p></li>
</ul>
</li>
<li><p><strong>Instance Types Available:</strong></p>
<ul class="simple">
<li><p>RTX 6000 Ada: 48GB VRAM, ~$0.75/hour</p></li>
<li><p>A10: 24GB VRAM, ~$0.60/hour</p></li>
<li><p>A100 (40GB): 40GB VRAM, ~$1.10/hour</p></li>
<li><p>A100 (80GB): 80GB VRAM, ~$1.40/hour</p></li>
<li><p>H100: 80GB VRAM, ~$2.50/hour (when available)</p></li>
</ul>
</li>
<li><p><strong>Access Instance:</strong></p>
<ul class="simple">
<li><p>Wait for instance to be “Running”</p></li>
<li><p>Note the public IP address</p></li>
<li><p>SSH: ssh ubuntu&#64;</p></li>
</ul>
</li>
</ol>
<p><strong>Follow this guide to set up your Lambda Cloud account and launch your first GPU instance.</strong></p>
</section>
<section id="Option-2:-API-Based-Setup">
<h3>Option 2: API-Based Setup<a class="headerlink" href="#Option-2:-API-Based-Setup" title="Link to this heading">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="k">class</span> <span class="nc">LambdaCloudAPI</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="n">api_key</span> <span class="ow">or</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">&#39;LAMBDA_API_KEY&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_url</span> <span class="o">=</span> <span class="s1">&#39;https://cloud.lambdalabs.com/api/v1&#39;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;Authorization&#39;</span><span class="p">:</span> <span class="sa">f</span><span class="s1">&#39;Bearer </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">api_key</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
            <span class="s1">&#39;Content-Type&#39;</span><span class="p">:</span> <span class="s1">&#39;application/json&#39;</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">list_instance_types</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;List available instance types.&quot;&quot;&quot;</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">base_url</span><span class="si">}</span><span class="s1">/instance-types&#39;</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">headers</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">list_instances</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;List running instances.&quot;&quot;&quot;</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">base_url</span><span class="si">}</span><span class="s1">/instances&#39;</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">headers</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">launch_instance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">instance_type</span><span class="p">,</span> <span class="n">ssh_key_name</span><span class="p">,</span> <span class="n">region</span><span class="o">=</span><span class="s1">&#39;us-east-1&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Launch a new instance.&quot;&quot;&quot;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;instance_type_name&#39;</span><span class="p">:</span> <span class="n">instance_type</span><span class="p">,</span>
            <span class="s1">&#39;ssh_key_names&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">ssh_key_name</span><span class="p">],</span>
            <span class="s1">&#39;region_name&#39;</span><span class="p">:</span> <span class="n">region</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">name</span><span class="p">:</span>
            <span class="n">data</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">name</span>

        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">base_url</span><span class="si">}</span><span class="s1">/instance-operations/launch&#39;</span><span class="p">,</span>
                               <span class="n">headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">headers</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">terminate_instance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">instance_id</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Terminate an instance.&quot;&quot;&quot;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;instance_ids&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">instance_id</span><span class="p">]}</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">base_url</span><span class="si">}</span><span class="s1">/instance-operations/terminate&#39;</span><span class="p">,</span>
                               <span class="n">headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">headers</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">get_instance_details</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">instance_id</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get detailed information about an instance.&quot;&quot;&quot;</span>
        <span class="n">instances</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_instances</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="n">instances</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="p">[]):</span>
            <span class="k">if</span> <span class="n">instance</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">instance_id</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">instance</span>
        <span class="k">return</span> <span class="kc">None</span>

<span class="c1"># Example usage:</span>
<span class="c1"># api = LambdaCloudAPI()</span>
<span class="c1"># instance_types = api.list_instance_types()</span>
<span class="c1"># print(json.dumps(instance_types, indent=2))</span>
</pre></div>
</div>
</div>
</section>
<section id="Lambda-Cloud-API-Setup-Guide">
<h3>Lambda Cloud API Setup Guide<a class="headerlink" href="#Lambda-Cloud-API-Setup-Guide" title="Link to this heading">¶</a></h3>
<section id="CLI-Setup-Steps">
<h4>CLI Setup Steps<a class="headerlink" href="#CLI-Setup-Steps" title="Link to this heading">¶</a></h4>
<ol class="arabic">
<li><p><strong>Get API Key:</strong></p>
<ul class="simple">
<li><p>Go to <a class="reference external" href="https://cloud.lambdalabs.com/api-keys">https://cloud.lambdalabs.com/api-keys</a></p></li>
<li><p>Generate a new API key</p></li>
<li><p>Set as environment variable: <code class="docutils literal notranslate"><span class="pre">export</span> <span class="pre">LAMBDA_API_KEY=&quot;your-key&quot;</span></code></p></li>
</ul>
</li>
<li><p><strong>Install Lambda Cloud CLI:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>lambda-cloud
lambda-cloud<span class="w"> </span>configure<span class="w">  </span><span class="c1"># Enter your API key</span>
</pre></div>
</div>
</li>
<li><p><strong>Basic CLI Commands:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># List available instance types</span>
lambda-cloud<span class="w"> </span>instance-types<span class="w"> </span>list

<span class="c1"># List available regions</span>
lambda-cloud<span class="w"> </span>regions<span class="w"> </span>list

<span class="c1"># Launch instance</span>
lambda-cloud<span class="w"> </span>instance<span class="w"> </span>launch<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--instance-type<span class="w"> </span>a100<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--ssh-key-name<span class="w"> </span>your-key-name<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--region<span class="w"> </span>us-east-1

<span class="c1"># List running instances</span>
lambda-cloud<span class="w"> </span>instance<span class="w"> </span>list

<span class="c1"># Terminate instance</span>
lambda-cloud<span class="w"> </span>instance<span class="w"> </span>terminate<span class="w"> </span>&lt;INSTANCE_ID&gt;
</pre></div>
</div>
</li>
</ol>
</section>
<section id="Python-API-Client">
<h4>Python API Client<a class="headerlink" href="#Python-API-Client" title="Link to this heading">¶</a></h4>
</section>
</section>
</section>
<section id="Configure-Clustrix-for-Lambda-Cloud">
<h2>Configure Clustrix for Lambda Cloud<a class="headerlink" href="#Configure-Clustrix-for-Lambda-Cloud" title="Link to this heading">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Configure Clustrix to use your Lambda Cloud instance</span>
<span class="n">configure</span><span class="p">(</span>
    <span class="n">cluster_type</span><span class="o">=</span><span class="s2">&quot;ssh&quot;</span><span class="p">,</span>
    <span class="n">cluster_host</span><span class="o">=</span><span class="s2">&quot;your-lambda-instance-ip&quot;</span><span class="p">,</span>  <span class="c1"># Replace with actual IP</span>
    <span class="n">username</span><span class="o">=</span><span class="s2">&quot;ubuntu&quot;</span><span class="p">,</span>  <span class="c1"># Default Lambda Cloud user</span>
    <span class="n">key_file</span><span class="o">=</span><span class="s2">&quot;~/.ssh/id_rsa&quot;</span><span class="p">,</span>  <span class="c1"># Your private SSH key</span>
    <span class="n">remote_work_dir</span><span class="o">=</span><span class="s2">&quot;/tmp/clustrix&quot;</span><span class="p">,</span>
    <span class="n">package_manager</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>  <span class="c1"># Will use uv if available</span>
    <span class="n">default_cores</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>  <span class="c1"># Lambda instances typically have 8+ cores</span>
    <span class="n">default_memory</span><span class="o">=</span><span class="s2">&quot;32GB&quot;</span><span class="p">,</span>  <span class="c1"># Generous memory allocation</span>
    <span class="n">default_time</span><span class="o">=</span><span class="s2">&quot;02:00:00&quot;</span><span class="p">,</span>  <span class="c1"># Longer timeout for GPU tasks</span>
    <span class="n">environment_variables</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">:</span> <span class="s2">&quot;0&quot;</span><span class="p">,</span>  <span class="c1"># Use first GPU</span>
        <span class="s2">&quot;NVIDIA_VISIBLE_DEVICES&quot;</span><span class="p">:</span> <span class="s2">&quot;all&quot;</span>
    <span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p><strong>Replace ``your-lambda-instance-ip`` with the actual IP address from your Lambda Cloud instance.</strong></p>
<section id="GPU-Verification-and-Setup">
<h3>GPU Verification and Setup<a class="headerlink" href="#GPU-Verification-and-Setup" title="Link to this heading">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@cluster</span><span class="p">(</span><span class="n">cores</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="s2">&quot;8GB&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">verify_lambda_gpu_setup</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Verify GPU availability and setup on Lambda Cloud instance.&quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">import</span> <span class="nn">subprocess</span>
    <span class="kn">import</span> <span class="nn">platform</span>

    <span class="c1"># System information</span>
    <span class="n">system_info</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;platform&#39;</span><span class="p">:</span> <span class="n">platform</span><span class="o">.</span><span class="n">platform</span><span class="p">(),</span>
        <span class="s1">&#39;python_version&#39;</span><span class="p">:</span> <span class="n">platform</span><span class="o">.</span><span class="n">python_version</span><span class="p">(),</span>
        <span class="s1">&#39;architecture&#39;</span><span class="p">:</span> <span class="n">platform</span><span class="o">.</span><span class="n">architecture</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="p">}</span>

    <span class="c1"># PyTorch and CUDA info</span>
    <span class="n">torch_info</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;pytorch_version&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
        <span class="s1">&#39;cuda_available&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">(),</span>
        <span class="s1">&#39;cuda_version&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">cuda</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;cudnn_version&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">version</span><span class="p">()</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="s1">&#39;device_count&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="p">}</span>

    <span class="c1"># GPU details</span>
    <span class="n">gpu_info</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()):</span>
            <span class="n">props</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">gpu_info</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;device_id&#39;</span><span class="p">:</span> <span class="n">i</span><span class="p">,</span>
                <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="n">props</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="s1">&#39;total_memory_gb&#39;</span><span class="p">:</span> <span class="n">props</span><span class="o">.</span><span class="n">total_memory</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">3</span><span class="p">),</span>
                <span class="s1">&#39;major&#39;</span><span class="p">:</span> <span class="n">props</span><span class="o">.</span><span class="n">major</span><span class="p">,</span>
                <span class="s1">&#39;minor&#39;</span><span class="p">:</span> <span class="n">props</span><span class="o">.</span><span class="n">minor</span><span class="p">,</span>
                <span class="s1">&#39;multiprocessor_count&#39;</span><span class="p">:</span> <span class="n">props</span><span class="o">.</span><span class="n">multi_processor_count</span>
            <span class="p">})</span>

    <span class="c1"># NVIDIA-SMI output</span>
    <span class="n">nvidia_smi</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="s1">&#39;nvidia-smi&#39;</span><span class="p">],</span> <span class="n">capture_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">returncode</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">nvidia_smi</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">stdout</span>
    <span class="k">except</span> <span class="ne">FileNotFoundError</span><span class="p">:</span>
        <span class="n">nvidia_smi</span> <span class="o">=</span> <span class="s2">&quot;nvidia-smi not found&quot;</span>

    <span class="c1"># Test GPU computation</span>
    <span class="n">gpu_test_result</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Simple GPU computation test</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

            <span class="n">start_time</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">end_time</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">Event</span><span class="p">(</span><span class="n">enable_timing</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">start_time</span><span class="o">.</span><span class="n">record</span><span class="p">()</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>
            <span class="n">end_time</span><span class="o">.</span><span class="n">record</span><span class="p">()</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>

            <span class="n">gpu_test_result</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;test_passed&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                <span class="s1">&#39;computation_time_ms&#39;</span><span class="p">:</span> <span class="n">start_time</span><span class="o">.</span><span class="n">elapsed_time</span><span class="p">(</span><span class="n">end_time</span><span class="p">),</span>
                <span class="s1">&#39;result_shape&#39;</span><span class="p">:</span> <span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                <span class="s1">&#39;memory_allocated_mb&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_allocated</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span>
                <span class="s1">&#39;memory_reserved_mb&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_reserved</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            <span class="p">}</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="n">gpu_test_result</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;test_passed&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
                <span class="s1">&#39;error&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
            <span class="p">}</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;system_info&#39;</span><span class="p">:</span> <span class="n">system_info</span><span class="p">,</span>
        <span class="s1">&#39;torch_info&#39;</span><span class="p">:</span> <span class="n">torch_info</span><span class="p">,</span>
        <span class="s1">&#39;gpu_info&#39;</span><span class="p">:</span> <span class="n">gpu_info</span><span class="p">,</span>
        <span class="s1">&#39;nvidia_smi&#39;</span><span class="p">:</span> <span class="n">nvidia_smi</span><span class="p">,</span>
        <span class="s1">&#39;gpu_test&#39;</span><span class="p">:</span> <span class="n">gpu_test_result</span>
    <span class="p">}</span>

<span class="c1"># Run GPU verification</span>
<span class="c1"># gpu_status = verify_lambda_gpu_setup()</span>
<span class="c1"># print(json.dumps(gpu_status, indent=2, default=str))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU verification function defined. Uncomment the lines above to run on Lambda Cloud.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Example-1:-Distributed-Deep-Learning-Training">
<h2>Example 1: Distributed Deep Learning Training<a class="headerlink" href="#Example-1:-Distributed-Deep-Learning-Training" title="Link to this heading">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@cluster</span><span class="p">(</span><span class="n">cores</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="s2">&quot;16GB&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">=</span><span class="s2">&quot;01:30:00&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">lambda_deep_learning_training</span><span class="p">(</span><span class="n">model_config</span><span class="p">,</span> <span class="n">training_config</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train a deep learning model on Lambda Cloud GPU.&quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
    <span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
    <span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
    <span class="kn">import</span> <span class="nn">time</span>

    <span class="c1"># Set device</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training on device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Create synthetic dataset</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="n">training_config</span><span class="p">[</span><span class="s1">&#39;n_samples&#39;</span><span class="p">]</span>
    <span class="n">n_features</span> <span class="o">=</span> <span class="n">training_config</span><span class="p">[</span><span class="s1">&#39;n_features&#39;</span><span class="p">]</span>
    <span class="n">n_classes</span> <span class="o">=</span> <span class="n">training_config</span><span class="p">[</span><span class="s1">&#39;n_classes&#39;</span><span class="p">]</span>

    <span class="c1"># Generate random data</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,))</span>

    <span class="c1"># Create dataset and dataloader</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">training_config</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">],</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="c1"># Define model architecture</span>
    <span class="k">class</span> <span class="nc">DeepNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.2</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">(</span><span class="n">DeepNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

            <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">prev_size</span> <span class="o">=</span> <span class="n">input_size</span>

            <span class="k">for</span> <span class="n">hidden_size</span> <span class="ow">in</span> <span class="n">hidden_sizes</span><span class="p">:</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">prev_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
                <span class="p">])</span>
                <span class="n">prev_size</span> <span class="o">=</span> <span class="n">hidden_size</span>

            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">prev_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">network</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># Create model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DeepNet</span><span class="p">(</span>
        <span class="n">input_size</span><span class="o">=</span><span class="n">n_features</span><span class="p">,</span>
        <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">model_config</span><span class="p">[</span><span class="s1">&#39;hidden_sizes&#39;</span><span class="p">],</span>
        <span class="n">output_size</span><span class="o">=</span><span class="n">n_classes</span><span class="p">,</span>
        <span class="n">dropout</span><span class="o">=</span><span class="n">model_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;dropout&#39;</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
    <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Loss and optimizer</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
        <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
        <span class="n">lr</span><span class="o">=</span><span class="n">training_config</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">],</span>
        <span class="n">weight_decay</span><span class="o">=</span><span class="n">training_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;weight_decay&#39;</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># Training loop</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">training_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="n">epoch_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">epoch_accuracies</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">training_config</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]):</span>
        <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>

        <span class="n">epoch_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_loss</span><span class="p">)</span>
        <span class="n">epoch_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">==</span> <span class="n">training_config</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">training_config</span><span class="p">[</span><span class="s2">&quot;epochs&quot;</span><span class="p">]</span><span class="si">}</span><span class="s1">: &#39;</span>
                  <span class="sa">f</span><span class="s1">&#39;Loss: </span><span class="si">{</span><span class="n">avg_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, Accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>

    <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">training_start</span>

    <span class="c1"># Model evaluation</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">test_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">test_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
        <span class="n">test_predictions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">test_output</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># Memory usage</span>
    <span class="n">memory_info</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">memory_info</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;allocated_mb&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_allocated</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span>
            <span class="s1">&#39;reserved_mb&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_reserved</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span>
            <span class="s1">&#39;max_allocated_mb&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">max_memory_allocated</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">}</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;training_completed&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s1">&#39;device_used&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
        <span class="s1">&#39;model_parameters&#39;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span>
        <span class="s1">&#39;trainable_parameters&#39;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">),</span>
        <span class="s1">&#39;training_time&#39;</span><span class="p">:</span> <span class="n">training_time</span><span class="p">,</span>
        <span class="s1">&#39;final_loss&#39;</span><span class="p">:</span> <span class="n">epoch_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
        <span class="s1">&#39;final_accuracy&#39;</span><span class="p">:</span> <span class="n">epoch_accuracies</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
        <span class="s1">&#39;best_accuracy&#39;</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="n">epoch_accuracies</span><span class="p">),</span>
        <span class="s1">&#39;epoch_losses&#39;</span><span class="p">:</span> <span class="n">epoch_losses</span><span class="p">,</span>
        <span class="s1">&#39;epoch_accuracies&#39;</span><span class="p">:</span> <span class="n">epoch_accuracies</span><span class="p">,</span>
        <span class="s1">&#39;memory_info&#39;</span><span class="p">:</span> <span class="n">memory_info</span><span class="p">,</span>
        <span class="s1">&#39;model_architecture&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="p">}</span>

<span class="c1"># Example configuration</span>
<span class="n">model_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;hidden_sizes&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span>
    <span class="s1">&#39;dropout&#39;</span><span class="p">:</span> <span class="mf">0.3</span>
<span class="p">}</span>

<span class="n">training_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;n_samples&#39;</span><span class="p">:</span> <span class="mi">10000</span><span class="p">,</span>
    <span class="s1">&#39;n_features&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s1">&#39;n_classes&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
    <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">1e-4</span>
<span class="p">}</span>

<span class="c1"># Run training</span>
<span class="c1"># result = lambda_deep_learning_training(model_config, training_config)</span>
<span class="c1"># print(f&quot;Training completed! Final accuracy: {result[&#39;final_accuracy&#39;]:.2f}%&quot;)</span>
<span class="c1"># print(f&quot;Training time: {result[&#39;training_time&#39;]:.2f} seconds&quot;)</span>
<span class="c1"># print(f&quot;GPU memory used: {result[&#39;memory_info&#39;].get(&#39;max_allocated_mb&#39;, 0):.1f} MB&quot;)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Deep learning training function defined. Uncomment the lines above to run on Lambda Cloud.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Example-2:-Transformer-Model-Fine-tuning">
<h2>Example 2: Transformer Model Fine-tuning<a class="headerlink" href="#Example-2:-Transformer-Model-Fine-tuning" title="Link to this heading">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@cluster</span><span class="p">(</span><span class="n">cores</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="s2">&quot;32GB&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">=</span><span class="s2">&quot;02:00:00&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">lambda_transformer_finetuning</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">training_params</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fine-tune a transformer model on Lambda Cloud GPU.&quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span>
        <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">,</span>
        <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">Trainer</span><span class="p">,</span> <span class="n">DataCollatorWithPadding</span>
    <span class="p">)</span>
    <span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">Dataset</span>
    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
    <span class="kn">import</span> <span class="nn">time</span>

    <span class="c1"># Set device</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fine-tuning on device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Load tokenizer and model</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="n">model_name</span><span class="p">,</span>
        <span class="n">num_labels</span><span class="o">=</span><span class="n">training_params</span><span class="p">[</span><span class="s1">&#39;num_labels&#39;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>

    <span class="c1"># Create synthetic dataset</span>
    <span class="k">def</span> <span class="nf">generate_synthetic_text_data</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate synthetic text classification data.&quot;&quot;&quot;</span>

        <span class="c1"># Simple text templates for different classes</span>
        <span class="n">templates</span> <span class="o">=</span> <span class="p">{</span>
            <span class="mi">0</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;This is a positive example about </span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;Great work on </span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;Excellent </span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">],</span>
            <span class="mi">1</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;This is a negative example about </span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;Poor </span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;Terrible </span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">],</span>
            <span class="mi">2</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;This is a neutral example about </span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;Average </span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;Okay </span><span class="si">{}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="k">if</span> <span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">2</span> <span class="k">else</span> <span class="p">[]</span>
        <span class="p">}</span>

        <span class="n">topics</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;technology&quot;</span><span class="p">,</span> <span class="s2">&quot;sports&quot;</span><span class="p">,</span> <span class="s2">&quot;food&quot;</span><span class="p">,</span> <span class="s2">&quot;movies&quot;</span><span class="p">,</span> <span class="s2">&quot;music&quot;</span><span class="p">,</span> <span class="s2">&quot;books&quot;</span><span class="p">,</span> <span class="s2">&quot;travel&quot;</span><span class="p">,</span> <span class="s2">&quot;science&quot;</span><span class="p">]</span>

        <span class="n">texts</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>
            <span class="n">template</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">templates</span><span class="p">[</span><span class="n">label</span><span class="p">])</span>
            <span class="n">topic</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">topics</span><span class="p">)</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">template</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">topic</span><span class="p">)</span>

            <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
            <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">texts</span><span class="p">,</span> <span class="n">labels</span>

    <span class="c1"># Generate data</span>
    <span class="n">train_texts</span><span class="p">,</span> <span class="n">train_labels</span> <span class="o">=</span> <span class="n">generate_synthetic_text_data</span><span class="p">(</span>
        <span class="n">training_params</span><span class="p">[</span><span class="s1">&#39;train_samples&#39;</span><span class="p">],</span> <span class="n">training_params</span><span class="p">[</span><span class="s1">&#39;num_labels&#39;</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">eval_texts</span><span class="p">,</span> <span class="n">eval_labels</span> <span class="o">=</span> <span class="n">generate_synthetic_text_data</span><span class="p">(</span>
        <span class="n">training_params</span><span class="p">[</span><span class="s1">&#39;eval_samples&#39;</span><span class="p">],</span> <span class="n">training_params</span><span class="p">[</span><span class="s1">&#39;num_labels&#39;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="c1"># Tokenize data</span>
    <span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">examples</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="n">training_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;max_length&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># Create datasets</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">train_texts</span><span class="p">,</span> <span class="s1">&#39;labels&#39;</span><span class="p">:</span> <span class="n">train_labels</span><span class="p">})</span>
    <span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">eval_texts</span><span class="p">,</span> <span class="s1">&#39;labels&#39;</span><span class="p">:</span> <span class="n">eval_labels</span><span class="p">})</span>

    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">eval_dataset</span> <span class="o">=</span> <span class="n">eval_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Data collator</span>
    <span class="n">data_collator</span> <span class="o">=</span> <span class="n">DataCollatorWithPadding</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>

    <span class="c1"># Training arguments</span>
    <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
        <span class="n">output_dir</span><span class="o">=</span><span class="s1">&#39;/tmp/results&#39;</span><span class="p">,</span>
        <span class="n">num_train_epochs</span><span class="o">=</span><span class="n">training_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;epochs&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
        <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="n">training_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
        <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="n">training_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;eval_batch_size&#39;</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
        <span class="n">warmup_steps</span><span class="o">=</span><span class="n">training_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;warmup_steps&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
        <span class="n">weight_decay</span><span class="o">=</span><span class="n">training_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;weight_decay&#39;</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">),</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="n">training_params</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="mf">2e-5</span><span class="p">),</span>
        <span class="n">logging_dir</span><span class="o">=</span><span class="s1">&#39;/tmp/logs&#39;</span><span class="p">,</span>
        <span class="n">logging_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
        <span class="n">save_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
        <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">metric_for_best_model</span><span class="o">=</span><span class="s2">&quot;eval_loss&quot;</span><span class="p">,</span>
        <span class="n">greater_is_better</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">fp16</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">(),</span>  <span class="c1"># Use mixed precision if GPU available</span>
        <span class="n">dataloader_pin_memory</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">(),</span>
        <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span>

    <span class="c1"># Define compute metrics</span>
    <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>
        <span class="n">predictions</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">accuracy</span><span class="p">}</span>

    <span class="c1"># Create trainer</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="n">eval_dataset</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
        <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span>
    <span class="p">)</span>

    <span class="c1"># Training</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">train_result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

    <span class="c1"># Final evaluation</span>
    <span class="n">eval_result</span> <span class="o">=</span> <span class="n">trainer</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()</span>

    <span class="c1"># Memory usage</span>
    <span class="n">memory_info</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">memory_info</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;allocated_mb&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_allocated</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span>
            <span class="s1">&#39;reserved_mb&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_reserved</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span>
            <span class="s1">&#39;max_allocated_mb&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">max_memory_allocated</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">}</span>

    <span class="c1"># Model info</span>
    <span class="n">total_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
    <span class="n">trainable_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="n">model_name</span><span class="p">,</span>
        <span class="s1">&#39;device_used&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
        <span class="s1">&#39;training_completed&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s1">&#39;training_time&#39;</span><span class="p">:</span> <span class="n">training_time</span><span class="p">,</span>
        <span class="s1">&#39;total_parameters&#39;</span><span class="p">:</span> <span class="n">total_params</span><span class="p">,</span>
        <span class="s1">&#39;trainable_parameters&#39;</span><span class="p">:</span> <span class="n">trainable_params</span><span class="p">,</span>
        <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="n">train_result</span><span class="o">.</span><span class="n">training_loss</span><span class="p">,</span>
        <span class="s1">&#39;eval_loss&#39;</span><span class="p">:</span> <span class="n">eval_result</span><span class="p">[</span><span class="s1">&#39;eval_loss&#39;</span><span class="p">],</span>
        <span class="s1">&#39;eval_accuracy&#39;</span><span class="p">:</span> <span class="n">eval_result</span><span class="p">[</span><span class="s1">&#39;eval_accuracy&#39;</span><span class="p">],</span>
        <span class="s1">&#39;train_steps&#39;</span><span class="p">:</span> <span class="n">train_result</span><span class="o">.</span><span class="n">global_step</span><span class="p">,</span>
        <span class="s1">&#39;memory_info&#39;</span><span class="p">:</span> <span class="n">memory_info</span><span class="p">,</span>
        <span class="s1">&#39;training_params&#39;</span><span class="p">:</span> <span class="n">training_params</span>
    <span class="p">}</span>

<span class="c1"># Example configuration</span>
<span class="n">training_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;num_labels&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="s1">&#39;train_samples&#39;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="s1">&#39;eval_samples&#39;</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
    <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
    <span class="s1">&#39;eval_batch_size&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">2e-5</span><span class="p">,</span>
    <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
    <span class="s1">&#39;warmup_steps&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s1">&#39;max_length&#39;</span><span class="p">:</span> <span class="mi">256</span>
<span class="p">}</span>

<span class="c1"># Run fine-tuning</span>
<span class="c1"># result = lambda_transformer_finetuning(&#39;distilbert-base-uncased&#39;, training_params)</span>
<span class="c1"># print(f&quot;Fine-tuning completed! Final accuracy: {result[&#39;eval_accuracy&#39;]:.4f}&quot;)</span>
<span class="c1"># print(f&quot;Training time: {result[&#39;training_time&#39;]:.2f} seconds&quot;)</span>
<span class="c1"># print(f&quot;Model parameters: {result[&#39;total_parameters&#39;]:,}&quot;)</span>
<span class="c1"># print(f&quot;GPU memory used: {result[&#39;memory_info&#39;].get(&#39;max_allocated_mb&#39;, 0):.1f} MB&quot;)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Transformer fine-tuning function defined. Uncomment the lines above to run on Lambda Cloud.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Example-3:-Computer-Vision-with-Large-Datasets">
<h2>Example 3: Computer Vision with Large Datasets<a class="headerlink" href="#Example-3:-Computer-Vision-with-Large-Datasets" title="Link to this heading">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@cluster</span><span class="p">(</span><span class="n">cores</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="s2">&quot;32GB&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">=</span><span class="s2">&quot;01:30:00&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">lambda_computer_vision_training</span><span class="p">(</span><span class="n">model_config</span><span class="p">,</span> <span class="n">data_config</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train a computer vision model on Lambda Cloud GPU.&quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
    <span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
    <span class="kn">import</span> <span class="nn">torchvision</span>
    <span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
    <span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
    <span class="kn">import</span> <span class="nn">time</span>

    <span class="c1"># Set device</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training computer vision model on device: </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Data augmentation and preprocessing</span>
    <span class="n">transform_train</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;image_size&#39;</span><span class="p">]),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="n">degrees</span><span class="o">=</span><span class="mi">15</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ColorJitter</span><span class="p">(</span><span class="n">brightness</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">contrast</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">saturation</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="p">])</span>

    <span class="n">transform_val</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToPILImage</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;image_size&#39;</span><span class="p">],</span> <span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;image_size&#39;</span><span class="p">])),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="p">])</span>

    <span class="c1"># Generate synthetic image data</span>
    <span class="k">def</span> <span class="nf">create_synthetic_images</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">n_channels</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create synthetic image dataset.&quot;&quot;&quot;</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">image_size</span><span class="p">,</span> <span class="n">n_channels</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span>

    <span class="c1"># Create datasets</span>
    <span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span> <span class="o">=</span> <span class="n">create_synthetic_images</span><span class="p">(</span>
        <span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;train_samples&#39;</span><span class="p">],</span>
        <span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;image_size&#39;</span><span class="p">],</span>
        <span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;n_channels&#39;</span><span class="p">],</span>
        <span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;n_classes&#39;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="n">val_images</span><span class="p">,</span> <span class="n">val_labels</span> <span class="o">=</span> <span class="n">create_synthetic_images</span><span class="p">(</span>
        <span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;val_samples&#39;</span><span class="p">],</span>
        <span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;image_size&#39;</span><span class="p">],</span>
        <span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;n_channels&#39;</span><span class="p">],</span>
        <span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;n_classes&#39;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="c1"># Custom dataset class</span>
    <span class="k">class</span> <span class="nc">SyntheticImageDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">images</span> <span class="o">=</span> <span class="n">images</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>

        <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">images</span><span class="p">)</span>

        <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">images</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">:</span>
                <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="mf">255.0</span>

            <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span>

    <span class="c1"># Create data loaders</span>
    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">SyntheticImageDataset</span><span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">transform_train</span><span class="p">)</span>
    <span class="n">val_dataset</span> <span class="o">=</span> <span class="n">SyntheticImageDataset</span><span class="p">(</span><span class="n">val_images</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">,</span> <span class="n">transform_val</span><span class="p">)</span>

    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">train_dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">],</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">False</span>
    <span class="p">)</span>

    <span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="n">val_dataset</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">],</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="kc">False</span>
    <span class="p">)</span>

    <span class="c1"># Model definition</span>
    <span class="k">if</span> <span class="n">model_config</span><span class="p">[</span><span class="s1">&#39;model_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;resnet&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">model_config</span><span class="p">[</span><span class="s1">&#39;pretrained&#39;</span><span class="p">]:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;n_classes&#39;</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;n_classes&#39;</span><span class="p">])</span>
    <span class="k">elif</span> <span class="n">model_config</span><span class="p">[</span><span class="s1">&#39;model_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;efficientnet&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">model_config</span><span class="p">[</span><span class="s1">&#39;pretrained&#39;</span><span class="p">]:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">efficientnet_b0</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">in_features</span><span class="p">,</span> <span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;n_classes&#39;</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">efficientnet_b0</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">data_config</span><span class="p">[</span><span class="s1">&#39;n_classes&#39;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported model type: </span><span class="si">{</span><span class="n">model_config</span><span class="p">[</span><span class="s1">&#39;model_type&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Loss and optimizer</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span>
        <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
        <span class="n">lr</span><span class="o">=</span><span class="n">model_config</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">],</span>
        <span class="n">weight_decay</span><span class="o">=</span><span class="n">model_config</span><span class="p">[</span><span class="s1">&#39;weight_decay&#39;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="c1"># Learning rate scheduler</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">CosineAnnealingLR</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="n">model_config</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="c1"># Training loop</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">val_accuracies</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">model_config</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]):</span>
        <span class="c1"># Training phase</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">avg_train_loss</span> <span class="o">=</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
        <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_train_loss</span><span class="p">)</span>

        <span class="c1"># Validation phase</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">val_loader</span><span class="p">:</span>
                <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="n">val_loss</span> <span class="o">+=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

                <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">total</span> <span class="o">+=</span> <span class="n">target</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">target</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">val_accuracy</span> <span class="o">=</span> <span class="mf">100.0</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
        <span class="n">val_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_accuracy</span><span class="p">)</span>

        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">epoch</span> <span class="o">==</span> <span class="n">model_config</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">/</span><span class="si">{</span><span class="n">model_config</span><span class="p">[</span><span class="s2">&quot;epochs&quot;</span><span class="p">]</span><span class="si">}</span><span class="s1">: &#39;</span>
                  <span class="sa">f</span><span class="s1">&#39;Train Loss: </span><span class="si">{</span><span class="n">avg_train_loss</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, &#39;</span>
                  <span class="sa">f</span><span class="s1">&#39;Val Accuracy: </span><span class="si">{</span><span class="n">val_accuracy</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%, &#39;</span>
                  <span class="sa">f</span><span class="s1">&#39;LR: </span><span class="si">{</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s1">.6f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="n">training_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>

    <span class="c1"># Memory usage</span>
    <span class="n">memory_info</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
        <span class="n">memory_info</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;allocated_mb&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_allocated</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span>
            <span class="s1">&#39;reserved_mb&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">memory_reserved</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="p">),</span>
            <span class="s1">&#39;max_allocated_mb&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">max_memory_allocated</span><span class="p">()</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1024</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">}</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;training_completed&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s1">&#39;device_used&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
        <span class="s1">&#39;model_type&#39;</span><span class="p">:</span> <span class="n">model_config</span><span class="p">[</span><span class="s1">&#39;model_type&#39;</span><span class="p">],</span>
        <span class="s1">&#39;model_parameters&#39;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span>
        <span class="s1">&#39;training_time&#39;</span><span class="p">:</span> <span class="n">training_time</span><span class="p">,</span>
        <span class="s1">&#39;final_train_loss&#39;</span><span class="p">:</span> <span class="n">train_losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
        <span class="s1">&#39;final_val_accuracy&#39;</span><span class="p">:</span> <span class="n">val_accuracies</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
        <span class="s1">&#39;best_val_accuracy&#39;</span><span class="p">:</span> <span class="nb">max</span><span class="p">(</span><span class="n">val_accuracies</span><span class="p">),</span>
        <span class="s1">&#39;train_losses&#39;</span><span class="p">:</span> <span class="n">train_losses</span><span class="p">,</span>
        <span class="s1">&#39;val_accuracies&#39;</span><span class="p">:</span> <span class="n">val_accuracies</span><span class="p">,</span>
        <span class="s1">&#39;memory_info&#39;</span><span class="p">:</span> <span class="n">memory_info</span><span class="p">,</span>
        <span class="s1">&#39;data_config&#39;</span><span class="p">:</span> <span class="n">data_config</span><span class="p">,</span>
        <span class="s1">&#39;model_config&#39;</span><span class="p">:</span> <span class="n">model_config</span>
    <span class="p">}</span>

<span class="c1"># Example configuration</span>
<span class="n">model_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;model_type&#39;</span><span class="p">:</span> <span class="s1">&#39;resnet&#39;</span><span class="p">,</span>  <span class="c1"># or &#39;efficientnet&#39;</span>
    <span class="s1">&#39;pretrained&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
    <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
    <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span> <span class="mf">1e-4</span>
<span class="p">}</span>

<span class="n">data_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;train_samples&#39;</span><span class="p">:</span> <span class="mi">5000</span><span class="p">,</span>
    <span class="s1">&#39;val_samples&#39;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span>
    <span class="s1">&#39;image_size&#39;</span><span class="p">:</span> <span class="mi">224</span><span class="p">,</span>
    <span class="s1">&#39;n_channels&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="s1">&#39;n_classes&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
    <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">32</span>
<span class="p">}</span>

<span class="c1"># Run training</span>
<span class="c1"># result = lambda_computer_vision_training(model_config, data_config)</span>
<span class="c1"># print(f&quot;CV training completed! Best accuracy: {result[&#39;best_val_accuracy&#39;]:.2f}%&quot;)</span>
<span class="c1"># print(f&quot;Training time: {result[&#39;training_time&#39;]:.2f} seconds&quot;)</span>
<span class="c1"># print(f&quot;Model parameters: {result[&#39;model_parameters&#39;]:,}&quot;)</span>
<span class="c1"># print(f&quot;GPU memory used: {result[&#39;memory_info&#39;].get(&#39;max_allocated_mb&#39;, 0):.1f} MB&quot;)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Computer vision training function defined. Uncomment the lines above to run on Lambda Cloud.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Multi-GPU-Training-on-Lambda-Cloud">
<h2>Multi-GPU Training on Lambda Cloud<a class="headerlink" href="#Multi-GPU-Training-on-Lambda-Cloud" title="Link to this heading">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@cluster</span><span class="p">(</span><span class="n">cores</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="s2">&quot;128GB&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">=</span><span class="s2">&quot;04:00:00&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">lambda_multi_gpu_training</span><span class="p">(</span><span class="n">model_config</span><span class="p">,</span> <span class="n">training_config</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multi-GPU training example using PyTorch DDP.&quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
    <span class="kn">import</span> <span class="nn">torch.multiprocessing</span> <span class="k">as</span> <span class="nn">mp</span>
    <span class="kn">from</span> <span class="nn">torch.nn.parallel</span> <span class="kn">import</span> <span class="n">DistributedDataParallel</span> <span class="k">as</span> <span class="n">DDP</span>
    <span class="kn">from</span> <span class="nn">torch.distributed</span> <span class="kn">import</span> <span class="n">init_process_group</span><span class="p">,</span> <span class="n">destroy_process_group</span>
    <span class="kn">import</span> <span class="nn">os</span>

    <span class="k">def</span> <span class="nf">setup_ddp</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Setup distributed data parallel.&quot;&quot;&quot;</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_ADDR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;localhost&#39;</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_PORT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;12355&#39;</span>
        <span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s2">&quot;nccl&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">cleanup_ddp</span><span class="p">():</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clean up distributed training.&quot;&quot;&quot;</span>
        <span class="n">destroy_process_group</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">train_on_gpu</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">training_config</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Training function for each GPU.&quot;&quot;&quot;</span>
        <span class="n">setup_ddp</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">)</span>

        <span class="c1"># Create model and move to GPU</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">model_config</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">DDP</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span>

        <span class="c1"># Create data loader with DistributedSampler</span>
        <span class="n">train_loader</span> <span class="o">=</span> <span class="n">create_distributed_dataloader</span><span class="p">(</span><span class="n">training_config</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">)</span>

        <span class="c1"># Training loop</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">training_config</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">])</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">training_config</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]):</span>
            <span class="n">train_loader</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">set_epoch</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>  <span class="c1"># Important for proper shuffling</span>

            <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
                <span class="n">data</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">rank</span><span class="p">),</span> <span class="n">target</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>

                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">, Batch </span><span class="si">{</span><span class="n">batch_idx</span><span class="si">}</span><span class="s1">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

        <span class="n">cleanup_ddp</span><span class="p">()</span>

    <span class="c1"># Launch multi-GPU training</span>
    <span class="n">world_size</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Starting multi-GPU training on </span><span class="si">{</span><span class="n">world_size</span><span class="si">}</span><span class="s2"> GPUs&quot;</span><span class="p">)</span>

    <span class="n">mp</span><span class="o">.</span><span class="n">spawn</span><span class="p">(</span>
        <span class="n">train_on_gpu</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">world_size</span><span class="p">,</span> <span class="n">model_config</span><span class="p">,</span> <span class="n">training_config</span><span class="p">),</span>
        <span class="n">nprocs</span><span class="o">=</span><span class="n">world_size</span><span class="p">,</span>
        <span class="n">join</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;training_completed&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;gpus_used&quot;</span><span class="p">:</span> <span class="n">world_size</span><span class="p">}</span>
</pre></div>
</div>
</div>
<section id="HuggingFace-Accelerate-Example">
<h3>HuggingFace Accelerate Example<a class="headerlink" href="#HuggingFace-Accelerate-Example" title="Link to this heading">¶</a></h3>
<p>Alternative approach using HuggingFace Accelerate for easier multi-GPU setup:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@cluster</span><span class="p">(</span><span class="n">cores</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="s2">&quot;128GB&quot;</span><span class="p">,</span> <span class="n">time</span><span class="o">=</span><span class="s2">&quot;04:00:00&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">lambda_accelerate_training</span><span class="p">(</span><span class="n">model_config</span><span class="p">,</span> <span class="n">training_config</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Multi-GPU training using HuggingFace Accelerate.&quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">accelerate</span> <span class="kn">import</span> <span class="n">Accelerator</span>
    <span class="kn">import</span> <span class="nn">torch</span>
    <span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

    <span class="c1"># Initialize accelerator</span>
    <span class="n">accelerator</span> <span class="o">=</span> <span class="n">Accelerator</span><span class="p">()</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">device</span>

    <span class="c1"># Create model and optimizer</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">create_model</span><span class="p">(</span><span class="n">model_config</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">training_config</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">])</span>
    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">create_dataloader</span><span class="p">(</span><span class="n">training_config</span><span class="p">)</span>

    <span class="c1"># Prepare for distributed training</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span> <span class="o">=</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_loader</span>
    <span class="p">)</span>

    <span class="c1"># Training loop</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">training_config</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">accumulate</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

                <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span> <span class="ow">and</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s1">, Batch </span><span class="si">{</span><span class="n">batch_idx</span><span class="si">}</span><span class="s1">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;training_completed&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;num_processes&quot;</span><span class="p">:</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">num_processes</span><span class="p">,</span>
        <span class="s2">&quot;device&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="p">}</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="id1">
<h2>Multi-GPU Training on Lambda Cloud<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h2>
<section id="Available-Multi-GPU-Instances">
<h3>Available Multi-GPU Instances<a class="headerlink" href="#Available-Multi-GPU-Instances" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>2x A100 (40GB)</strong>: ~$2.20/hour</p></li>
<li><p><strong>4x A100 (40GB)</strong>: ~$4.40/hour</p></li>
<li><p><strong>8x A100 (40GB)</strong>: ~$8.80/hour</p></li>
<li><p><strong>2x A100 (80GB)</strong>: ~$2.80/hour</p></li>
<li><p><strong>4x A100 (80GB)</strong>: ~$5.60/hour</p></li>
<li><p><strong>8x A100 (80GB)</strong>: ~$11.20/hour</p></li>
<li><p><strong>8x H100</strong>: ~$20.00/hour (when available)</p></li>
</ul>
</section>
<section id="Setup-Requirements">
<h3>Setup Requirements<a class="headerlink" href="#Setup-Requirements" title="Link to this heading">¶</a></h3>
<ol class="arabic">
<li><p><strong>Launch multi-GPU instance</strong> via Lambda Cloud console</p></li>
<li><p><strong>Install additional packages</strong> for distributed training:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>accelerate<span class="w"> </span>deepspeed
</pre></div>
</div>
</li>
<li><p><strong>Configure Clustrix</strong> for multi-GPU environment</p></li>
<li><p><strong>Use appropriate parallelization strategy</strong></p></li>
</ol>
</section>
<section id="Parallelization-Strategies">
<h3>Parallelization Strategies<a class="headerlink" href="#Parallelization-Strategies" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>Data Parallel (DP)</strong>: Simple, works for most models</p></li>
<li><p><strong>Distributed Data Parallel (DDP)</strong>: Better performance, recommended</p></li>
<li><p><strong>Model Parallel</strong>: For very large models that don’t fit on single GPU</p></li>
<li><p><strong>Pipeline Parallel</strong>: For extremely large models</p></li>
<li><p><strong>DeepSpeed ZeRO</strong>: For memory-efficient training of large models</p></li>
</ul>
</section>
<section id="PyTorch-DDP-Example">
<h3>PyTorch DDP Example<a class="headerlink" href="#PyTorch-DDP-Example" title="Link to this heading">¶</a></h3>
</section>
</section>
<section id="Cost-Optimization-Strategies">
<h2>Cost Optimization Strategies<a class="headerlink" href="#Cost-Optimization-Strategies" title="Link to this heading">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import Clustrix cost monitoring functionality</span>
<span class="kn">from</span> <span class="nn">clustrix</span> <span class="kn">import</span> <span class="n">cost_tracking_decorator</span><span class="p">,</span> <span class="n">get_cost_monitor</span><span class="p">,</span> <span class="n">generate_cost_report</span>

<span class="c1"># Example 1: Using the cost tracking decorator</span>
<span class="nd">@cost_tracking_decorator</span><span class="p">(</span><span class="s1">&#39;lambda&#39;</span><span class="p">,</span> <span class="s1">&#39;a100_40gb&#39;</span><span class="p">)</span>
<span class="nd">@cluster</span><span class="p">(</span><span class="n">cores</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="s2">&quot;32GB&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">lambda_training_with_cost_tracking</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Example training function with automatic cost tracking.&quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">time</span>
    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

    <span class="c1"># Simulate training workload</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting training...&quot;</span><span class="p">)</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Simulate 2 seconds of work</span>

    <span class="c1"># Simulate some compute</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training completed!&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;model_accuracy&#39;</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span>
        <span class="s1">&#39;training_samples&#39;</span><span class="p">:</span> <span class="mi">10000</span><span class="p">,</span>
        <span class="s1">&#39;final_loss&#39;</span><span class="p">:</span> <span class="mf">0.032</span>
    <span class="p">}</span>

<span class="c1"># Example 2: Manual cost monitoring</span>
<span class="k">def</span> <span class="nf">manual_cost_monitoring_example</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Example of manual cost monitoring.&quot;&quot;&quot;</span>
    <span class="c1"># Start cost monitoring</span>
    <span class="n">monitor</span> <span class="o">=</span> <span class="n">get_cost_monitor</span><span class="p">(</span><span class="s1">&#39;lambda&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">monitor</span><span class="p">:</span>
        <span class="n">monitor</span><span class="o">.</span><span class="n">start_monitoring</span><span class="p">()</span>

        <span class="c1"># Your computation here</span>
        <span class="kn">import</span> <span class="nn">time</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Stop monitoring and get report</span>
        <span class="n">cost_report</span> <span class="o">=</span> <span class="n">monitor</span><span class="o">.</span><span class="n">stop_monitoring</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">cost_report</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Computation completed in </span><span class="si">{</span><span class="n">cost_report</span><span class="o">.</span><span class="n">duration_seconds</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> seconds&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Estimated cost: $</span><span class="si">{</span><span class="n">cost_report</span><span class="o">.</span><span class="n">cost_estimate</span><span class="o">.</span><span class="n">estimated_cost</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GPU utilization: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">cost_report</span><span class="o">.</span><span class="n">resource_usage</span><span class="o">.</span><span class="n">gpu_stats</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="p">[])</span><span class="si">}</span><span class="s2"> GPUs&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">cost_report</span><span class="o">.</span><span class="n">recommendations</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cost optimization recommendations:&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">rec</span> <span class="ow">in</span> <span class="n">cost_report</span><span class="o">.</span><span class="n">recommendations</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - </span><span class="si">{</span><span class="n">rec</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Example 3: Generate real-time cost report</span>
<span class="k">def</span> <span class="nf">get_current_cost_status</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get current cost and resource status.&quot;&quot;&quot;</span>
    <span class="n">report</span> <span class="o">=</span> <span class="n">generate_cost_report</span><span class="p">(</span><span class="s1">&#39;lambda&#39;</span><span class="p">,</span> <span class="s1">&#39;a100_40gb&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">report</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Current Lambda Cloud Status:&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  CPU Usage: </span><span class="si">{</span><span class="n">report</span><span class="p">[</span><span class="s1">&#39;resource_usage&#39;</span><span class="p">][</span><span class="s1">&#39;cpu_percent&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Memory Usage: </span><span class="si">{</span><span class="n">report</span><span class="p">[</span><span class="s1">&#39;resource_usage&#39;</span><span class="p">][</span><span class="s1">&#39;memory_percent&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">report</span><span class="p">[</span><span class="s1">&#39;resource_usage&#39;</span><span class="p">][</span><span class="s1">&#39;gpu_stats&#39;</span><span class="p">]:</span>
            <span class="n">avg_gpu</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">gpu</span><span class="p">[</span><span class="s1">&#39;utilization_percent&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">gpu</span> <span class="ow">in</span> <span class="n">report</span><span class="p">[</span><span class="s1">&#39;resource_usage&#39;</span><span class="p">][</span><span class="s1">&#39;gpu_stats&#39;</span><span class="p">])</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">report</span><span class="p">[</span><span class="s1">&#39;resource_usage&#39;</span><span class="p">][</span><span class="s1">&#39;gpu_stats&#39;</span><span class="p">])</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  GPU Usage: </span><span class="si">{</span><span class="n">avg_gpu</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Hourly Rate: $</span><span class="si">{</span><span class="n">report</span><span class="p">[</span><span class="s1">&#39;cost_estimate&#39;</span><span class="p">][</span><span class="s1">&#39;hourly_rate&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Example 4: Compare pricing across instance types</span>
<span class="k">def</span> <span class="nf">compare_lambda_pricing</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compare pricing for different Lambda Cloud instance types.&quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">clustrix</span> <span class="kn">import</span> <span class="n">get_pricing_info</span>

    <span class="n">pricing</span> <span class="o">=</span> <span class="n">get_pricing_info</span><span class="p">(</span><span class="s1">&#39;lambda&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pricing</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Lambda Cloud Instance Pricing (USD/hour):&quot;</span><span class="p">)</span>

        <span class="c1"># Group by category</span>
        <span class="n">single_gpu</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">pricing</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">((</span><span class="s1">&#39;2x&#39;</span><span class="p">,</span> <span class="s1">&#39;4x&#39;</span><span class="p">,</span> <span class="s1">&#39;8x&#39;</span><span class="p">))</span> <span class="ow">and</span> <span class="n">k</span> <span class="o">!=</span> <span class="s1">&#39;default&#39;</span><span class="p">}</span>
        <span class="n">multi_gpu</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">pricing</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">((</span><span class="s1">&#39;2x&#39;</span><span class="p">,</span> <span class="s1">&#39;4x&#39;</span><span class="p">,</span> <span class="s1">&#39;8x&#39;</span><span class="p">))}</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Single GPU Instances:&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">instance</span><span class="p">,</span> <span class="n">price</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">single_gpu</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">instance</span><span class="si">:</span><span class="s2">&lt;15</span><span class="si">}</span><span class="s2">: $</span><span class="si">{</span><span class="n">price</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">/hour&quot;</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Multi-GPU Instances:&quot;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">instance</span><span class="p">,</span> <span class="n">price</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">multi_gpu</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">instance</span><span class="si">:</span><span class="s2">&lt;15</span><span class="si">}</span><span class="s2">: $</span><span class="si">{</span><span class="n">price</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">/hour&quot;</span><span class="p">)</span>

<span class="c1"># Run examples (uncomment to test)</span>
<span class="c1"># print(&quot;1. Cost tracking decorator example:&quot;)</span>
<span class="c1"># result = lambda_training_with_cost_tracking()</span>
<span class="c1"># print(f&quot;Training result: {result}&quot;)</span>

<span class="c1"># print(&quot;\n2. Manual cost monitoring example:&quot;)</span>
<span class="c1"># manual_cost_monitoring_example()</span>

<span class="c1"># print(&quot;\n3. Current cost status:&quot;)</span>
<span class="c1"># get_current_cost_status()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;4. Lambda Cloud pricing comparison:&quot;</span><span class="p">)</span>
<span class="n">compare_lambda_pricing</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✅ Lambda Cloud cost monitoring examples ready!&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;💡 Use @cost_tracking_decorator(&#39;lambda&#39;, &#39;instance_type&#39;) for automatic cost tracking&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Lambda-Cloud-Cost-Optimization">
<h2>Lambda Cloud Cost Optimization<a class="headerlink" href="#Lambda-Cloud-Cost-Optimization" title="Link to this heading">¶</a></h2>
<section id="Cost-Monitoring-and-Tracking">
<h3>Cost Monitoring and Tracking<a class="headerlink" href="#Cost-Monitoring-and-Tracking" title="Link to this heading">¶</a></h3>
<p>Monitor GPU utilization and track costs effectively:</p>
</section>
<section id="id2">
<h3>Lambda Cloud Cost Optimization<a class="headerlink" href="#id2" title="Link to this heading">¶</a></h3>
<section id="💰-Instance-Selection">
<h4>💰 Instance Selection<a class="headerlink" href="#💰-Instance-Selection" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p><strong>RTX 6000 Ada</strong>: Best value for most ML workloads (~$0.75/hour)</p></li>
<li><p><strong>A10</strong>: Good balance of performance and cost (~$0.60/hour)</p></li>
<li><p><strong>A100 40GB</strong>: For large models requiring more VRAM (~$1.10/hour)</p></li>
<li><p><strong>A100 80GB</strong>: Only when 40GB is insufficient (~$1.40/hour)</p></li>
<li><p><strong>H100</strong>: Premium option for cutting-edge research (~$2.50/hour)</p></li>
</ul>
</section>
<section id="⏰-Usage-Patterns">
<h4>⏰ Usage Patterns<a class="headerlink" href="#⏰-Usage-Patterns" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>Use “persistent” instances for ongoing development</p></li>
<li><p>Terminate instances immediately after training completion</p></li>
<li><p>Schedule training jobs during off-peak hours if possible</p></li>
<li><p>Use local development for debugging, GPU for final training</p></li>
</ul>
</section>
<section id="🔧-Optimization-Techniques">
<h4>🔧 Optimization Techniques<a class="headerlink" href="#🔧-Optimization-Techniques" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>Mixed precision training (fp16) to reduce memory usage</p></li>
<li><p>Gradient accumulation for effective larger batch sizes</p></li>
<li><p>Model checkpointing to resume interrupted training</p></li>
<li><p>Efficient data loading with multiple workers</p></li>
<li><p>Early stopping to avoid overtraining</p></li>
</ul>
</section>
<section id="📊-Monitoring-and-Management">
<h4>📊 Monitoring and Management<a class="headerlink" href="#📊-Monitoring-and-Management" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>Monitor GPU utilization with nvidia-smi</p></li>
<li><p>Track training progress with logging</p></li>
<li><p>Set training time limits to prevent runaway costs</p></li>
<li><p>Use Clustrix timeouts as safety nets</p></li>
<li><p>Regular cost reviews and budget alerts</p></li>
</ul>
</section>
<section id="🚀-Clustrix-Specific-Optimizations">
<h4>🚀 Clustrix-Specific Optimizations<a class="headerlink" href="#🚀-Clustrix-Specific-Optimizations" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>Use Clustrix auto-cleanup features</p></li>
<li><p>Implement job queuing for multiple experiments</p></li>
<li><p>Leverage Clustrix’s timeout mechanisms</p></li>
<li><p>Use remote environment caching</p></li>
</ul>
</section>
</section>
</section>
<section id="Best-Practices-and-Troubleshooting">
<h2>Best Practices and Troubleshooting<a class="headerlink" href="#Best-Practices-and-Troubleshooting" title="Link to this heading">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Example usage of monitoring functions</span>
<span class="k">def</span> <span class="nf">create_monitoring_script</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create and save the GPU monitoring script.&quot;&quot;&quot;</span>
    <span class="n">script_content</span> <span class="o">=</span> <span class="s1">&#39;&#39;&#39;#!/bin/bash</span>
<span class="s1"># Lambda Cloud monitoring script</span>

<span class="s1">echo &quot;Lambda Cloud Training Monitor&quot;</span>
<span class="s1">echo &quot;============================&quot;</span>
<span class="s1">echo &quot;Start time: $(date)&quot;</span>
<span class="s1">echo &quot;&quot;</span>

<span class="s1"># System information</span>
<span class="s1">echo &quot;System Information:&quot;</span>
<span class="s1">echo &quot;------------------&quot;</span>
<span class="s1">nvidia-smi --query-gpu=gpu_name,memory.total,power.draw --format=csv</span>
<span class="s1">echo &quot;&quot;</span>

<span class="s1"># Monitor GPU usage every 30 seconds</span>
<span class="s1">while true; do</span>
<span class="s1">    echo &quot;GPU Status at $(date):&quot;</span>
<span class="s1">    nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu --format=csv,noheader</span>
<span class="s1">    echo &quot;&quot;</span>

<span class="s1">    # Check if training process is still running</span>
<span class="s1">    if ! pgrep -f python &gt; /dev/null; then</span>
<span class="s1">        echo &quot;No Python processes found. Training may have completed.&quot;</span>
<span class="s1">        break</span>
<span class="s1">    fi</span>

<span class="s1">    sleep 30</span>
<span class="s1">done</span>

<span class="s1">echo &quot;Monitoring completed at $(date)&quot;</span>
<span class="s1">&#39;&#39;&#39;</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;monitor_training.sh&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">script_content</span><span class="p">)</span>

    <span class="c1"># Make executable</span>
    <span class="kn">import</span> <span class="nn">os</span>
    <span class="n">os</span><span class="o">.</span><span class="n">chmod</span><span class="p">(</span><span class="s1">&#39;monitor_training.sh&#39;</span><span class="p">,</span> <span class="mo">0o755</span><span class="p">)</span>

    <span class="k">return</span> <span class="s2">&quot;Monitoring script created: monitor_training.sh&quot;</span>

<span class="c1"># Uncomment to create the monitoring script:</span>
<span class="c1"># result = create_monitoring_script()</span>
<span class="c1"># print(result)</span>
</pre></div>
</div>
</div>
</section>
<section id="Lambda-Cloud-Best-Practices">
<h2>Lambda Cloud Best Practices<a class="headerlink" href="#Lambda-Cloud-Best-Practices" title="Link to this heading">¶</a></h2>
<section id="GPU-Monitoring-Script">
<h3>GPU Monitoring Script<a class="headerlink" href="#GPU-Monitoring-Script" title="Link to this heading">¶</a></h3>
<p>Use this monitoring script to track GPU usage during training. Save as <code class="docutils literal notranslate"><span class="pre">monitor_training.sh</span></code> and run with: <code class="docutils literal notranslate"><span class="pre">bash</span> <span class="pre">monitor_training.sh</span></code></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1"># Lambda Cloud monitoring script</span>

<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Lambda Cloud Training Monitor&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;============================&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Start time: </span><span class="k">$(</span>date<span class="k">)</span><span class="s2">&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;&quot;</span>

<span class="c1"># System information</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;System Information:&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;------------------&quot;</span>
nvidia-smi<span class="w"> </span>--query-gpu<span class="o">=</span>gpu_name,memory.total,power.draw<span class="w"> </span>--format<span class="o">=</span>csv
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;&quot;</span>

<span class="c1"># Monitor GPU usage every 30 seconds</span>
<span class="k">while</span><span class="w"> </span>true<span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;GPU Status at </span><span class="k">$(</span>date<span class="k">)</span><span class="s2">:&quot;</span>
<span class="w">    </span>nvidia-smi<span class="w"> </span>--query-gpu<span class="o">=</span>utilization.gpu,memory.used,memory.total,temperature.gpu<span class="w"> </span>--format<span class="o">=</span>csv,noheader
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;&quot;</span>

<span class="w">    </span><span class="c1"># Check if training process is still running</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span>!<span class="w"> </span>pgrep<span class="w"> </span>-f<span class="w"> </span>python<span class="w"> </span>&gt;<span class="w"> </span>/dev/null<span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">        </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;No Python processes found. Training may have completed.&quot;</span>
<span class="w">        </span><span class="k">break</span>
<span class="w">    </span><span class="k">fi</span>

<span class="w">    </span>sleep<span class="w"> </span><span class="m">30</span>
<span class="k">done</span>

<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Monitoring completed at </span><span class="k">$(</span>date<span class="k">)</span><span class="s2">&quot;</span>
</pre></div>
</div>
</section>
<section id="Lambda-Cloud-+-Clustrix-Best-Practices">
<h3>Lambda Cloud + Clustrix Best Practices<a class="headerlink" href="#Lambda-Cloud-+-Clustrix-Best-Practices" title="Link to this heading">¶</a></h3>
<section id="🚀-Performance-Optimization">
<h4>🚀 Performance Optimization<a class="headerlink" href="#🚀-Performance-Optimization" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>Always use mixed precision (fp16) when possible</p></li>
<li><p>Optimize data loading with multiple workers and pin_memory</p></li>
<li><p>Use appropriate batch sizes to maximize GPU utilization</p></li>
<li><p>Enable tensor cores for compatible operations</p></li>
<li><p>Pre-allocate GPU memory to avoid fragmentation</p></li>
</ul>
</section>
<section id="💾-Data-Management">
<h4>💾 Data Management<a class="headerlink" href="#💾-Data-Management" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>Store datasets on fast NVMe storage when available</p></li>
<li><p>Use data streaming for very large datasets</p></li>
<li><p>Implement efficient data preprocessing pipelines</p></li>
<li><p>Cache frequently used data in memory</p></li>
<li><p>Use appropriate data formats (e.g., HDF5, Parquet)</p></li>
</ul>
</section>
<section id="🔧-Environment-Setup">
<h4>🔧 Environment Setup<a class="headerlink" href="#🔧-Environment-Setup" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>Use conda environments for reproducible setups</p></li>
<li><p>Pin package versions in requirements.txt</p></li>
<li><p>Install packages from conda-forge when possible</p></li>
<li><p>Use uv package manager for faster installs</p></li>
<li><p>Set up proper CUDA environment variables</p></li>
</ul>
</section>
<section id="🛠️-Development-Workflow">
<h4>🛠️ Development Workflow<a class="headerlink" href="#🛠️-Development-Workflow" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>Develop and debug locally, train on Lambda Cloud</p></li>
<li><p>Use small datasets for initial testing</p></li>
<li><p>Implement proper logging and monitoring</p></li>
<li><p>Save model checkpoints regularly</p></li>
<li><p>Use version control for experiment tracking</p></li>
</ul>
</section>
<section id="🔒-Security">
<h4>🔒 Security<a class="headerlink" href="#🔒-Security" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>Use SSH keys instead of passwords</p></li>
<li><p>Keep SSH keys secure and rotate regularly</p></li>
<li><p>Don’t store credentials in code or notebooks</p></li>
<li><p>Use environment variables for configuration</p></li>
<li><p>Monitor instance access logs</p></li>
</ul>
</section>
</section>
<section id="Common-Issues-and-Solutions">
<h3>Common Issues and Solutions<a class="headerlink" href="#Common-Issues-and-Solutions" title="Link to this heading">¶</a></h3>
<section id="❌-CUDA-out-of-memory-errors">
<h4>❌ CUDA out of memory errors<a class="headerlink" href="#❌-CUDA-out-of-memory-errors" title="Link to this heading">¶</a></h4>
<p>✅ <strong>Solutions:</strong></p>
<ul class="simple">
<li><p>Reduce batch size</p></li>
<li><p>Enable gradient checkpointing</p></li>
<li><p>Use mixed precision training</p></li>
<li><p>Clear GPU cache with torch.cuda.empty_cache()</p></li>
<li><p>Consider model parallelism for large models</p></li>
</ul>
</section>
<section id="❌-Slow-data-loading">
<h4>❌ Slow data loading<a class="headerlink" href="#❌-Slow-data-loading" title="Link to this heading">¶</a></h4>
<p>✅ <strong>Solutions:</strong></p>
<ul class="simple">
<li><p>Increase num_workers in DataLoader</p></li>
<li><p>Enable pin_memory for GPU transfers</p></li>
<li><p>Use faster storage (NVMe over network storage)</p></li>
<li><p>Implement data prefetching</p></li>
<li><p>Optimize data preprocessing</p></li>
</ul>
</section>
<section id="❌-SSH-connection-timeouts">
<h4>❌ SSH connection timeouts<a class="headerlink" href="#❌-SSH-connection-timeouts" title="Link to this heading">¶</a></h4>
<p>✅ <strong>Solutions:</strong></p>
<ul class="simple">
<li><p>Configure SSH keep-alive settings</p></li>
<li><p>Use screen or tmux for long-running jobs</p></li>
<li><p>Implement proper error handling in Clustrix</p></li>
<li><p>Set appropriate timeout values</p></li>
<li><p>Monitor network connectivity</p></li>
</ul>
</section>
<section id="❌-Low-GPU-utilization">
<h4>❌ Low GPU utilization<a class="headerlink" href="#❌-Low-GPU-utilization" title="Link to this heading">¶</a></h4>
<p>✅ <strong>Solutions:</strong></p>
<ul class="simple">
<li><p>Increase batch size if memory allows</p></li>
<li><p>Optimize data loading pipeline</p></li>
<li><p>Use asynchronous data transfers</p></li>
<li><p>Profile code to identify bottlenecks</p></li>
<li><p>Consider multi-GPU training</p></li>
</ul>
</section>
<section id="❌-Package-installation-failures">
<h4>❌ Package installation failures<a class="headerlink" href="#❌-Package-installation-failures" title="Link to this heading">¶</a></h4>
<p>✅ <strong>Solutions:</strong></p>
<ul class="simple">
<li><p>Use conda for system-level packages</p></li>
<li><p>Check CUDA compatibility versions</p></li>
<li><p>Clear pip cache if needed</p></li>
<li><p>Use –no-cache-dir flag for pip</p></li>
<li><p>Install packages in correct order</p></li>
</ul>
</section>
</section>
</section>
<section id="Instance-Management-and-Cleanup">
<h2>Instance Management and Cleanup<a class="headerlink" href="#Instance-Management-and-Cleanup" title="Link to this heading">¶</a></h2>
<section id="Lambda-Cloud-Instance-Management">
<h3>Lambda Cloud Instance Management<a class="headerlink" href="#Lambda-Cloud-Instance-Management" title="Link to this heading">¶</a></h3>
<section id="🔍-Check-Running-Instances">
<h4>🔍 Check Running Instances<a class="headerlink" href="#🔍-Check-Running-Instances" title="Link to this heading">¶</a></h4>
<p><strong>Via CLI:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>lambda-cloud<span class="w"> </span>instance<span class="w"> </span>list
</pre></div>
</div>
<p><strong>Via Web Console:</strong> Visit: <a class="reference external" href="https://cloud.lambdalabs.com/instances">https://cloud.lambdalabs.com/instances</a></p>
</section>
<section id="⏹️-Terminate-Instances">
<h4>⏹️ Terminate Instances<a class="headerlink" href="#⏹️-Terminate-Instances" title="Link to this heading">¶</a></h4>
<p><strong>Terminate specific instance:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>lambda-cloud<span class="w"> </span>instance<span class="w"> </span>terminate<span class="w"> </span>&lt;INSTANCE_ID&gt;
</pre></div>
</div>
<p><strong>Terminate all instances (DANGEROUS!):</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>lambda-cloud<span class="w"> </span>instance<span class="w"> </span>list<span class="w"> </span>--format<span class="o">=</span>csv<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-v<span class="w"> </span><span class="s2">&quot;instance_id&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>cut<span class="w"> </span>-d<span class="s1">&#39;,&#39;</span><span class="w"> </span>-f1<span class="w"> </span><span class="p">|</span><span class="w"> </span>xargs<span class="w"> </span>-I<span class="w"> </span><span class="o">{}</span><span class="w"> </span>lambda-cloud<span class="w"> </span>instance<span class="w"> </span>terminate<span class="w"> </span><span class="o">{}</span>
</pre></div>
</div>
</section>
<section id="💾-Save-Work-Before-Termination">
<h4>💾 Save Work Before Termination<a class="headerlink" href="#💾-Save-Work-Before-Termination" title="Link to this heading">¶</a></h4>
<p><strong>Save models to persistent storage:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>rsync<span class="w"> </span>-avz<span class="w"> </span>ubuntu@&lt;INSTANCE_IP&gt;:/path/to/models/<span class="w"> </span>./local_models/
</pre></div>
</div>
<p><strong>Save logs and results:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>scp<span class="w"> </span>-r<span class="w"> </span>ubuntu@&lt;INSTANCE_IP&gt;:/tmp/clustrix/<span class="w"> </span>./results/
</pre></div>
</div>
</section>
<section id="📊-Cost-Monitoring">
<h4>📊 Cost Monitoring<a class="headerlink" href="#📊-Cost-Monitoring" title="Link to this heading">¶</a></h4>
<p><strong>Check current usage:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>lambda-cloud<span class="w"> </span>instance<span class="w"> </span>list<span class="w"> </span>--format<span class="o">=</span>table
</pre></div>
</div>
<p><strong>Estimate costs:</strong></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>lambda-cloud<span class="w"> </span>instance<span class="w"> </span>list<span class="w"> </span>--format<span class="o">=</span>csv<span class="w"> </span><span class="p">|</span><span class="w"> </span>awk<span class="w"> </span>-F<span class="s1">&#39;,&#39;</span><span class="w"> </span><span class="s1">&#39;NR&gt;1 {print $2, $3}&#39;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="k">while</span><span class="w"> </span><span class="nb">read</span><span class="w"> </span><span class="nb">type</span><span class="w"> </span>status<span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="s2">&quot;</span><span class="nv">$status</span><span class="s2">&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">&quot;active&quot;</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">        </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Active instance: </span><span class="nv">$type</span><span class="s2">&quot;</span>
<span class="w">    </span><span class="k">fi</span>
<span class="k">done</span>
</pre></div>
</div>
</section>
</section>
<section id="Automated-Cleanup-Script">
<h3>Automated Cleanup Script<a class="headerlink" href="#Automated-Cleanup-Script" title="Link to this heading">¶</a></h3>
<p>Save this as <code class="docutils literal notranslate"><span class="pre">lambda_cleanup.sh</span></code> for automated instance management:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1"># Automated cleanup script for Lambda Cloud</span>
<span class="c1"># Save as lambda_cleanup.sh</span>

<span class="nb">set</span><span class="w"> </span>-e

<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Lambda Cloud Automated Cleanup&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;==============================&quot;</span>

<span class="c1"># Check if lambda-cloud CLI is installed</span>
<span class="k">if</span><span class="w"> </span>!<span class="w"> </span><span class="nb">command</span><span class="w"> </span>-v<span class="w"> </span>lambda-cloud<span class="w"> </span><span class="p">&amp;</span>&gt;<span class="w"> </span>/dev/null<span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Error: lambda-cloud CLI not found. Please install it first.&quot;</span>
<span class="w">    </span><span class="nb">exit</span><span class="w"> </span><span class="m">1</span>
<span class="k">fi</span>

<span class="c1"># List current instances</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Current instances:&quot;</span>
lambda-cloud<span class="w"> </span>instance<span class="w"> </span>list
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;&quot;</span>

<span class="c1"># Ask for confirmation</span>
<span class="nb">read</span><span class="w"> </span>-p<span class="w"> </span><span class="s2">&quot;Do you want to terminate ALL instances? (y/N): &quot;</span><span class="w"> </span>-n<span class="w"> </span><span class="m">1</span><span class="w"> </span>-r
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;&quot;</span>
<span class="k">if</span><span class="w"> </span><span class="o">[[</span><span class="w"> </span>!<span class="w"> </span><span class="nv">$REPLY</span><span class="w"> </span><span class="o">=</span>~<span class="w"> </span>^<span class="o">[</span>Yy<span class="o">]</span>$<span class="w"> </span><span class="o">]]</span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Cleanup cancelled.&quot;</span>
<span class="w">    </span><span class="nb">exit</span><span class="w"> </span><span class="m">0</span>
<span class="k">fi</span>

<span class="c1"># Get instance IDs</span>
<span class="nv">INSTANCE_IDS</span><span class="o">=</span><span class="k">$(</span>lambda-cloud<span class="w"> </span>instance<span class="w"> </span>list<span class="w"> </span>--format<span class="o">=</span>csv<span class="w"> </span><span class="p">|</span><span class="w"> </span>grep<span class="w"> </span>-v<span class="w"> </span><span class="s2">&quot;instance_id&quot;</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>cut<span class="w"> </span>-d<span class="s1">&#39;,&#39;</span><span class="w"> </span>-f1<span class="k">)</span>

<span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span>-z<span class="w"> </span><span class="s2">&quot;</span><span class="nv">$INSTANCE_IDS</span><span class="s2">&quot;</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;No instances to terminate.&quot;</span>
<span class="w">    </span><span class="nb">exit</span><span class="w"> </span><span class="m">0</span>
<span class="k">fi</span>

<span class="c1"># Terminate instances</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Terminating instances...&quot;</span>
<span class="k">for</span><span class="w"> </span>instance_id<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nv">$INSTANCE_IDS</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">    </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Terminating instance: </span><span class="nv">$instance_id</span><span class="s2">&quot;</span>
<span class="w">    </span>lambda-cloud<span class="w"> </span>instance<span class="w"> </span>terminate<span class="w"> </span><span class="nv">$instance_id</span>
<span class="k">done</span>

<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;All instances terminated.&quot;</span>
<span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Please verify termination in the web console: https://cloud.lambdalabs.com/instances&quot;</span>
</pre></div>
</div>
</section>
<section id="Clustrix-Integration-Manager">
<h3>Clustrix Integration Manager<a class="headerlink" href="#Clustrix-Integration-Manager" title="Link to this heading">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Integrate cleanup with Clustrix workflows</span>

<span class="kn">from</span> <span class="nn">clustrix</span> <span class="kn">import</span> <span class="n">configure</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="k">class</span> <span class="nc">LambdaCloudManager</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Manager for Lambda Cloud instances with Clustrix integration.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">active_instances</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">launch_instance_for_clustrix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">instance_type</span><span class="p">,</span> <span class="n">ssh_key_name</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Launch instance and configure Clustrix.&quot;&quot;&quot;</span>
        <span class="c1"># Launch instance</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span>
            <span class="s1">&#39;lambda-cloud&#39;</span><span class="p">,</span> <span class="s1">&#39;instance&#39;</span><span class="p">,</span> <span class="s1">&#39;launch&#39;</span><span class="p">,</span>
            <span class="s1">&#39;--instance-type&#39;</span><span class="p">,</span> <span class="n">instance_type</span><span class="p">,</span>
            <span class="s1">&#39;--ssh-key-name&#39;</span><span class="p">,</span> <span class="n">ssh_key_name</span>
        <span class="p">],</span> <span class="n">capture_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">returncode</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to launch instance: </span><span class="si">{</span><span class="n">result</span><span class="o">.</span><span class="n">stderr</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Parse instance ID and IP (simplified)</span>
        <span class="n">instance_id</span> <span class="o">=</span> <span class="s2">&quot;extracted_from_output&quot;</span>  <span class="c1"># Parse from result.stdout</span>
        <span class="n">instance_ip</span> <span class="o">=</span> <span class="s2">&quot;extracted_from_output&quot;</span>   <span class="c1"># Parse from result.stdout</span>

        <span class="c1"># Wait for instance to be ready</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">60</span><span class="p">)</span>  <span class="c1"># Wait for startup</span>

        <span class="c1"># Configure Clustrix</span>
        <span class="n">configure</span><span class="p">(</span>
            <span class="n">cluster_type</span><span class="o">=</span><span class="s2">&quot;ssh&quot;</span><span class="p">,</span>
            <span class="n">cluster_host</span><span class="o">=</span><span class="n">instance_ip</span><span class="p">,</span>
            <span class="n">username</span><span class="o">=</span><span class="s2">&quot;ubuntu&quot;</span><span class="p">,</span>
            <span class="n">key_file</span><span class="o">=</span><span class="s2">&quot;~/.ssh/id_rsa&quot;</span><span class="p">,</span>
            <span class="n">remote_work_dir</span><span class="o">=</span><span class="s2">&quot;/tmp/clustrix&quot;</span><span class="p">,</span>
            <span class="n">package_manager</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
            <span class="n">cleanup_on_success</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">active_instances</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s1">&#39;id&#39;</span><span class="p">:</span> <span class="n">instance_id</span><span class="p">,</span>
            <span class="s1">&#39;ip&#39;</span><span class="p">:</span> <span class="n">instance_ip</span><span class="p">,</span>
            <span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="n">instance_type</span><span class="p">,</span>
            <span class="s1">&#39;launch_time&#39;</span><span class="p">:</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="p">})</span>

        <span class="k">return</span> <span class="n">instance_id</span><span class="p">,</span> <span class="n">instance_ip</span>

    <span class="k">def</span> <span class="nf">cleanup_all_instances</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clean up all managed instances.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">instance</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">active_instances</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span>
                    <span class="s1">&#39;lambda-cloud&#39;</span><span class="p">,</span> <span class="s1">&#39;instance&#39;</span><span class="p">,</span> <span class="s1">&#39;terminate&#39;</span><span class="p">,</span> <span class="n">instance</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span>
                <span class="p">],</span> <span class="n">check</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Terminated instance </span><span class="si">{</span><span class="n">instance</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">except</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">CalledProcessError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to terminate </span><span class="si">{</span><span class="n">instance</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">active_instances</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

    <span class="k">def</span> <span class="fm">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Ensure cleanup on object destruction.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">active_instances</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Warning: Active instances detected. Cleaning up...&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cleanup_all_instances</span><span class="p">()</span>

<span class="c1"># Usage example:</span>
<span class="c1"># manager = LambdaCloudManager()</span>
<span class="c1"># try:</span>
<span class="c1">#     instance_id, ip = manager.launch_instance_for_clustrix(&#39;a100&#39;, &#39;my-ssh-key&#39;)</span>
<span class="c1">#     # Run your Clustrix computations</span>
<span class="c1">#     result = my_clustrix_function()</span>
<span class="c1"># finally:</span>
<span class="c1">#     manager.cleanup_all_instances()</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Summary">
<h2>Summary<a class="headerlink" href="#Summary" title="Link to this heading">¶</a></h2>
<p>This tutorial covered:</p>
<ol class="arabic simple">
<li><p><strong>Setup</strong>: Lambda Cloud account creation and instance management</p></li>
<li><p><strong>GPU Computing</strong>: High-performance GPU instances for ML workloads</p></li>
<li><p><strong>Deep Learning</strong>: PyTorch training with GPU acceleration</p></li>
<li><p><strong>Transformer Models</strong>: Fine-tuning with HuggingFace Transformers</p></li>
<li><p><strong>Computer Vision</strong>: CNN training with data augmentation</p></li>
<li><p><strong>Multi-GPU Training</strong>: Distributed training across multiple GPUs</p></li>
<li><p><strong>Cost Optimization</strong>: Strategies to minimize GPU computing costs</p></li>
<li><p><strong>Best Practices</strong>: Performance optimization and troubleshooting</p></li>
<li><p><strong>Instance Management</strong>: Automated cleanup and monitoring</p></li>
</ol>
<section id="Key-Advantages-of-Lambda-Cloud-+-Clustrix">
<h3>Key Advantages of Lambda Cloud + Clustrix<a class="headerlink" href="#Key-Advantages-of-Lambda-Cloud-+-Clustrix" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>GPU Focus</strong>: Specialized in high-performance GPU computing</p></li>
<li><p><strong>Cost Effective</strong>: Competitive pricing for GPU instances</p></li>
<li><p><strong>Simple Management</strong>: Easy instance launching and termination</p></li>
<li><p><strong>High Performance</strong>: Latest NVIDIA GPUs (A100, H100, RTX)</p></li>
<li><p><strong>Fast Networking</strong>: InfiniBand for multi-GPU communication</p></li>
<li><p><strong>ML Optimized</strong>: Pre-configured environments for machine learning</p></li>
<li><p><strong>Flexible Scaling</strong>: From single GPU to large multi-GPU clusters</p></li>
</ul>
</section>
<section id="Lambda-Cloud-Pricing-Advantages">
<h3>Lambda Cloud Pricing Advantages<a class="headerlink" href="#Lambda-Cloud-Pricing-Advantages" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>RTX 6000 Ada</strong>: Excellent price/performance for most ML workloads</p></li>
<li><p><strong>A100 40GB/80GB</strong>: Industry-standard for large-scale training</p></li>
<li><p><strong>H100</strong>: Cutting-edge performance for the most demanding workloads</p></li>
<li><p><strong>Multi-GPU</strong>: Cost-effective scaling for distributed training</p></li>
<li><p><strong>No Hidden Fees</strong>: Simple per-hour pricing</p></li>
</ul>
</section>
<section id="Next-Steps">
<h3>Next Steps<a class="headerlink" href="#Next-Steps" title="Link to this heading">¶</a></h3>
<ol class="arabic simple">
<li><p>Create your Lambda Cloud account and add SSH keys</p></li>
<li><p>Start with a single GPU instance for testing</p></li>
<li><p>Configure Clustrix for your Lambda Cloud instance</p></li>
<li><p>Run the provided examples to verify setup</p></li>
<li><p>Scale to multi-GPU instances for larger workloads</p></li>
<li><p>Implement cost monitoring and automated cleanup</p></li>
</ol>
</section>
<section id="Use-Cases">
<h3>Use Cases<a class="headerlink" href="#Use-Cases" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><strong>Deep Learning Research</strong>: Train large neural networks efficiently</p></li>
<li><p><strong>Computer Vision</strong>: Process large image datasets with CNNs</p></li>
<li><p><strong>NLP</strong>: Fine-tune transformer models on custom datasets</p></li>
<li><p><strong>Scientific Computing</strong>: GPU-accelerated simulations and modeling</p></li>
<li><p><strong>Prototyping</strong>: Rapid experimentation with different architectures</p></li>
<li><p><strong>Production Training</strong>: Scale up successful experiments</p></li>
</ul>
</section>
<section id="Resources">
<h3>Resources<a class="headerlink" href="#Resources" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://cloud.lambdalabs.com/">Lambda Cloud Console</a></p></li>
<li><p><a class="reference external" href="https://lambdalabs.com/service/gpu-cloud/documentation">Lambda Cloud Documentation</a></p></li>
<li><p><a class="reference external" href="https://github.com/LambdaLabsML/lambda-cloud-cli">Lambda Cloud CLI</a></p></li>
<li><p><a class="reference external" href="https://pytorch.org/docs/">PyTorch Documentation</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/transformers/">HuggingFace Transformers</a></p></li>
<li><p><a class="reference external" href="https://clustrix.readthedocs.io/">Clustrix Documentation</a></p></li>
</ul>
<p><strong>Remember</strong>: Lambda Cloud excels at GPU computing! Always terminate instances when not in use to control costs, and leverage Clustrix’s distributed computing capabilities to scale your ML workloads efficiently.</p>
</section>
</section>
</section>

</main>
                        <nav aria-label="Page navigation" class="py-4 my-5 clearfix font-weight-bold border-top">
    <a class="float-left" href="huggingface_spaces_tutorial.html" title="Previous">
        <span aria-hidden="true">←&nbsp;</span>HuggingFace Spaces Tutorial
    </a>
    <a class="float-right" href="cost_monitoring_tutorial.html" title="Next">
        Cloud Cost Monitoring and Optimization <span aria-hidden="true">&nbsp;→</span>
    </a>
</nav>
                    </div>
                    
                    <nav class="col-12 col-lg-3 pb-4">
                        <div class="sticky-top toc page-toc" aria-labelledby="page-toc-heading">
                            <p class="font-weight-bold" id="page-toc-heading">Page contents</p>
                            <ul>
<li><a class="reference internal" href="#">Lambda Cloud Tutorial</a><ul>
<li><a class="reference internal" href="#Overview">Overview</a></li>
<li><a class="reference internal" href="#Prerequisites">Prerequisites</a></li>
<li><a class="reference internal" href="#Installation-and-Setup">Installation and Setup</a></li>
<li><a class="reference internal" href="#Lambda-Cloud-Authentication-and-Setup">Lambda Cloud Authentication and Setup</a><ul>
<li><a class="reference internal" href="#Option-1:-Web-Console-Setup">Option 1: Web Console Setup</a></li>
<li><a class="reference internal" href="#Lambda-Cloud-Web-Console-Setup">Lambda Cloud Web Console Setup</a></li>
<li><a class="reference internal" href="#Option-2:-API-Based-Setup">Option 2: API-Based Setup</a></li>
<li><a class="reference internal" href="#Lambda-Cloud-API-Setup-Guide">Lambda Cloud API Setup Guide</a><ul>
<li><a class="reference internal" href="#CLI-Setup-Steps">CLI Setup Steps</a></li>
<li><a class="reference internal" href="#Python-API-Client">Python API Client</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#Configure-Clustrix-for-Lambda-Cloud">Configure Clustrix for Lambda Cloud</a><ul>
<li><a class="reference internal" href="#GPU-Verification-and-Setup">GPU Verification and Setup</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Example-1:-Distributed-Deep-Learning-Training">Example 1: Distributed Deep Learning Training</a></li>
<li><a class="reference internal" href="#Example-2:-Transformer-Model-Fine-tuning">Example 2: Transformer Model Fine-tuning</a></li>
<li><a class="reference internal" href="#Example-3:-Computer-Vision-with-Large-Datasets">Example 3: Computer Vision with Large Datasets</a></li>
<li><a class="reference internal" href="#Multi-GPU-Training-on-Lambda-Cloud">Multi-GPU Training on Lambda Cloud</a><ul>
<li><a class="reference internal" href="#HuggingFace-Accelerate-Example">HuggingFace Accelerate Example</a></li>
</ul>
</li>
<li><a class="reference internal" href="#id1">Multi-GPU Training on Lambda Cloud</a><ul>
<li><a class="reference internal" href="#Available-Multi-GPU-Instances">Available Multi-GPU Instances</a></li>
<li><a class="reference internal" href="#Setup-Requirements">Setup Requirements</a></li>
<li><a class="reference internal" href="#Parallelization-Strategies">Parallelization Strategies</a></li>
<li><a class="reference internal" href="#PyTorch-DDP-Example">PyTorch DDP Example</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Cost-Optimization-Strategies">Cost Optimization Strategies</a></li>
<li><a class="reference internal" href="#Lambda-Cloud-Cost-Optimization">Lambda Cloud Cost Optimization</a><ul>
<li><a class="reference internal" href="#Cost-Monitoring-and-Tracking">Cost Monitoring and Tracking</a></li>
<li><a class="reference internal" href="#id2">Lambda Cloud Cost Optimization</a><ul>
<li><a class="reference internal" href="#💰-Instance-Selection">💰 Instance Selection</a></li>
<li><a class="reference internal" href="#⏰-Usage-Patterns">⏰ Usage Patterns</a></li>
<li><a class="reference internal" href="#🔧-Optimization-Techniques">🔧 Optimization Techniques</a></li>
<li><a class="reference internal" href="#📊-Monitoring-and-Management">📊 Monitoring and Management</a></li>
<li><a class="reference internal" href="#🚀-Clustrix-Specific-Optimizations">🚀 Clustrix-Specific Optimizations</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#Best-Practices-and-Troubleshooting">Best Practices and Troubleshooting</a></li>
<li><a class="reference internal" href="#Lambda-Cloud-Best-Practices">Lambda Cloud Best Practices</a><ul>
<li><a class="reference internal" href="#GPU-Monitoring-Script">GPU Monitoring Script</a></li>
<li><a class="reference internal" href="#Lambda-Cloud-+-Clustrix-Best-Practices">Lambda Cloud + Clustrix Best Practices</a><ul>
<li><a class="reference internal" href="#🚀-Performance-Optimization">🚀 Performance Optimization</a></li>
<li><a class="reference internal" href="#💾-Data-Management">💾 Data Management</a></li>
<li><a class="reference internal" href="#🔧-Environment-Setup">🔧 Environment Setup</a></li>
<li><a class="reference internal" href="#🛠️-Development-Workflow">🛠️ Development Workflow</a></li>
<li><a class="reference internal" href="#🔒-Security">🔒 Security</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Common-Issues-and-Solutions">Common Issues and Solutions</a><ul>
<li><a class="reference internal" href="#❌-CUDA-out-of-memory-errors">❌ CUDA out of memory errors</a></li>
<li><a class="reference internal" href="#❌-Slow-data-loading">❌ Slow data loading</a></li>
<li><a class="reference internal" href="#❌-SSH-connection-timeouts">❌ SSH connection timeouts</a></li>
<li><a class="reference internal" href="#❌-Low-GPU-utilization">❌ Low GPU utilization</a></li>
<li><a class="reference internal" href="#❌-Package-installation-failures">❌ Package installation failures</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#Instance-Management-and-Cleanup">Instance Management and Cleanup</a><ul>
<li><a class="reference internal" href="#Lambda-Cloud-Instance-Management">Lambda Cloud Instance Management</a><ul>
<li><a class="reference internal" href="#🔍-Check-Running-Instances">🔍 Check Running Instances</a></li>
<li><a class="reference internal" href="#⏹️-Terminate-Instances">⏹️ Terminate Instances</a></li>
<li><a class="reference internal" href="#💾-Save-Work-Before-Termination">💾 Save Work Before Termination</a></li>
<li><a class="reference internal" href="#📊-Cost-Monitoring">📊 Cost Monitoring</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Automated-Cleanup-Script">Automated Cleanup Script</a></li>
<li><a class="reference internal" href="#Clustrix-Integration-Manager">Clustrix Integration Manager</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Summary">Summary</a><ul>
<li><a class="reference internal" href="#Key-Advantages-of-Lambda-Cloud-+-Clustrix">Key Advantages of Lambda Cloud + Clustrix</a></li>
<li><a class="reference internal" href="#Lambda-Cloud-Pricing-Advantages">Lambda Cloud Pricing Advantages</a></li>
<li><a class="reference internal" href="#Next-Steps">Next Steps</a></li>
<li><a class="reference internal" href="#Use-Cases">Use Cases</a></li>
<li><a class="reference internal" href="#Resources">Resources</a></li>
</ul>
</li>
</ul>
</li>
</ul>

                        </div>
                    </nav>
                    
                </div>
            </div>
        </div>
    </div>
    <footer class="container-fluid bg-primary text-light">
        <div class="container">
            <div class="row">
        <div class="col p-4">
            
                <nav aria-label="Footer">
                    <ul class="nav justify-content-center mb-2">
                        
                            
                            
                            <li class="nav-item"><a class="nav-link text-light"  href="PyPI">GitHub</a></li>
                        
                    </ul>
                </nav>
            
            <div class="text-center">
                    &copy; Copyright 2025, Contextual Dynamics Laboratory
            </div>
            <div class="text-center text-white-50 font-italic mt-3">
                <small>Last updated: Jun 28, 2025</small>
                <small>
                    Created using
                    <a class="text-white" href="https://github.com/wagtail/sphinx_wagtail_theme" rel="nofollow" target="_blank">
                        Sphinx Wagtail Theme 6.5.0
                    </a>
                    and
                    <a class="text-white" href="https://www.sphinx-doc.org/" rel="nofollow" target="_blank">
                        Sphinx 8.1.3
                    </a>
                </small>
            </div>
        </div>
    </div>
        </div>
    </footer>
        <script src="../_static/documentation_options.js?v=01f34227"></script>
        <script src="../_static/doctools.js?v=9bcbadda"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../_static/copybutton.js?v=f281be69"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <script type="text/javascript" src="../_static/dist/theme.js"></script>
        <script type="text/javascript" src="../_static/dist/vendor.js"></script>
        <script type="text/javascript" src="../_static/searchtools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script type="text/javascript">
            document.addEventListener('DOMContentLoaded', function() { Search.loadIndex("../searchindex.js"); });
        </script>
        <script type="text/javascript" id="searchindexloader"></script>
    </body>
</html>