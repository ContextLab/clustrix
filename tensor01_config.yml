# Clustrix configuration for tensor01.dartmouth.edu SSH cluster
cluster_type: "ssh"
cluster_host: "tensor01.dartmouth.edu"
username: "f002d6b"
remote_work_dir: "/tmp/clustrix_tensor01"
python_executable: "python3"

# Authentication configuration
use_1password: true
onepassword_note: "clustrix-ssh-gpu"
use_env_password: true
password_env_var: "CLUSTRIX_PASSWORD"

# SSH defaults
default_cores: 4
default_memory: "8GB"
default_time: "00:15:00"

# Cluster-specific environment setup
module_loads:
  - "python"
  - "cuda"

environment_variables:
  OMP_NUM_THREADS: "1"
  # CUDA_VISIBLE_DEVICES: "0"  # Commented out to allow detection of all 8 GPUs

# Commands to run before creating virtual environment
pre_execution_commands:
  - "export PATH=/usr/bin:$PATH"
  - "which python3 || echo 'Python3 not found in PATH'"
  - "module list"

# Cluster-specific packages to install in VENV2 (tensor01 has GPU support)
cluster_packages:
  # Install PyTorch with CUDA support for modern Python (conda environment)
  - package: "torch torchvision torchaudio"
    pip_args: "--index-url https://download.pytorch.org/whl/cu118"
    timeout: 600
  # Install TensorFlow with GPU support
  - package: "tensorflow"
    timeout: 600
  # Install additional GPU utilities
  - "nvidia-ml-py3"
  - "gpustat"

# Commands to run after package installation in VENV2
venv_post_install_commands:
  - "python -c \"import torch; print('PyTorch version:', torch.__version__); print('CUDA available:', torch.cuda.is_available()); print('CUDA devices:', torch.cuda.device_count() if torch.cuda.is_available() else 'No CUDA')\" || echo 'PyTorch test failed'"
  - "python -c \"import tensorflow as tf; print('TensorFlow version:', tf.__version__); print('GPU devices:', len(tf.config.list_physical_devices('GPU')) if hasattr(tf.config, 'list_physical_devices') else 'GPU detection unavailable')\" || echo 'TensorFlow test failed'"
  - "nvidia-smi || echo 'nvidia-smi not available'"

# VERIFIED WORKING (2025-07-12):
# - 8x NVIDIA RTX A6000 GPUs with 49GB VRAM each
# - PyTorch 2.7.1+cu118 with CUDA support  
# - Python 3.9.23 in conda environment
# - Basic GPU tensor operations confirmed
# 
# FUNCTION DESIGN GUIDELINES:
# ✅ Simple functions work reliably (< 20 lines, single subprocess)
# ❌ Complex functions may fail (> 30 lines, multiple operations)
# 
# RECOMMENDED PATTERN:
# @cluster(cores=1, memory="4GB")  
# def simple_gpu_task():
#     import subprocess
#     result = subprocess.run(["python", "-c", "import torch; ..."], ...)
#     return parsed_result